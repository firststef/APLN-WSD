{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy sklearn rowordnet\n",
        "!python -m spacy download ro_core_news_lg\n",
        "!pip install bs4\n",
        "!pip install sparknlp pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1hfFcVwCFi7",
        "outputId": "018045b6-0619-4558-d7b3-30e1c870e31c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.4.4)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (0.0.post2)\n",
            "Requirement already satisfied: rowordnet in /usr/local/lib/python3.8/dist-packages (1.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.4)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from rowordnet) (4.9.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from rowordnet) (3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ro-core-news-lg==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ro_core_news_lg-3.4.0/ro_core_news_lg-3.4.0-py3-none-any.whl (568.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.5/568.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from ro-core-news-lg==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (3.0.11)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (2.25.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (1.10.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (21.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (8.1.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (4.0.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->ro-core-news-lg==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ro_core_news_lg')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.8/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from bs4) (4.6.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sparknlp in /usr/local/lib/python3.8/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: spark-nlp in /usr/local/lib/python3.8/dist-packages (from sparknlp) (4.2.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sparknlp) (1.21.6)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functia de parsare a fiserului xml**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "v4DCbHKpgETs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlEYrj0n8zzy",
        "outputId": "5c4b9228-4937-4b9e-ea71-c73421f161c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['lac', 'lin', 'mare', 'masa', 'opus', 'pană', 'păr', 'para', 'nouă', 'bancă', 'barem', 'broască', 'călca', 'car', 'colonie', 'consola', 'casa', 'acaju', 'accident', 'acru', 'afină', 'agățătoare', 'alpaca', 'abate', 'anticar', 'antrenor', 'arici', 'vin', 'veselă', 'vâna', 'umbrele', 'turele', 'torturi', 'toc', 'sare', 'republica', 'paria', 'somn', 'post', 'sol', 'poartă', 'ochi', 'mobilă', 'mie', 'formă', 'corn', 'coș', 'fata', 'fila', 'folie', 'haină', 'imobil', 'curele', 'copii'])\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def parse_xml(path):\n",
        "  with open(path, encoding='utf8') as fp:\n",
        "    file_p = fp.read()\n",
        "    soup = BeautifulSoup(file_p, 'html.parser')\n",
        "  data = soup.find_all('instance')\n",
        "  parsed_data = {}\n",
        "  for sense in data:\n",
        "    new_data = []\n",
        "    # pentru fiecare sens, extragem id si contextele \n",
        "    contexts = sense.find_all('context')\n",
        "    senseId = sense.attrs[\"id\"][10:]\n",
        "    if len(senseId)<=1:\n",
        "      break\n",
        "    word = sense.attrs[\"word\"]\n",
        "    for context in contexts:\n",
        "      try:\n",
        "\n",
        "        sentence = context.decode_contents().strip('\\n')\n",
        "        a, *b = sentence.split('<head>')\n",
        "        b, *c = ''.join(b).split('</head>')\n",
        "        sentence = a + b + ''.join(c)\n",
        "        sentence= ' '.join(sentence.split())\n",
        "        \n",
        "        new_data.append((sentence, senseId))\n",
        "          \n",
        "      except:\n",
        "        continue\n",
        "    if word =='':\n",
        "      continue\n",
        "    # grupam sensurile pe cuvinte\n",
        "    if word in parsed_data:\n",
        "      parsed_data[word].extend(new_data)\n",
        "    else:\n",
        "      parsed_data[word] = new_data\n",
        "     \n",
        "  return parsed_data\n",
        "\n",
        "\n",
        "\n",
        "prep_data = parse_xml(\"/content/drive/MyDrive/wsd/data_wsd/toate.xml\")\n",
        "print(prep_data.keys())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functia de splituire, care imparte datele in date de antrenare si date de test**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "y_33s4e8hUHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def split_data(data):\n",
        "  train_data = {}\n",
        "  test_data = {}\n",
        "  for word, vector in data.items():\n",
        "    if(len({item[1] for item in vector})<2):\n",
        "      continue\n",
        "    senses = {}\n",
        "    for tup in vector:\n",
        "      context, sense = tup\n",
        "      if sense not in senses:\n",
        "        senses[sense] = []\n",
        "      senses[sense].append(tup)\n",
        "\n",
        "    train_data[word] = []\n",
        "    test_data[word] = []\n",
        "\n",
        "\n",
        "    for sense in senses:\n",
        "      vec = senses[sense]\n",
        "      l = len(vec)\n",
        "      marg = 2*l//3\n",
        "      if l < 3:\n",
        "        pass\n",
        "\n",
        "      else:\n",
        "        random.shuffle(vec)\n",
        "        ex_train = vec[:marg]\n",
        "        ex_test = vec[marg:]\n",
        "        train_data[word].extend(ex_train)\n",
        "        test_data[word].extend(ex_test)\n",
        "  return train_data, test_data\n",
        "\n",
        "train_data, test_data = split_data(prep_data)\n",
        "print(train_data.keys())\n",
        "print(prep_data.keys())\n",
        "print(train_data[\"lac\"])\n",
        "print(test_data[\"lac\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzGEtRZyO6jv",
        "outputId": "9b5a97fa-dcd7-46a3-9a01-c4e87a33c882"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['lac', 'lin', 'mare', 'masa', 'opus', 'pană', 'păr', 'para', 'nouă', 'bancă', 'broască', 'călca', 'car', 'colonie', 'consola', 'casa', 'accident', 'acru', 'alpaca', 'abate', 'anticar', 'vin', 'veselă', 'vâna', 'umbrele', 'turele', 'torturi', 'toc', 'sare', 'republica', 'paria', 'somn', 'post', 'sol', 'poartă', 'ochi', 'mobilă', 'mie', 'formă', 'corn', 'fata', 'imobil'])\n",
            "dict_keys(['lac', 'lin', 'mare', 'masa', 'opus', 'pană', 'păr', 'para', 'nouă', 'bancă', 'barem', 'broască', 'călca', 'car', 'colonie', 'consola', 'casa', 'acaju', 'accident', 'acru', 'afină', 'agățătoare', 'alpaca', 'abate', 'anticar', 'antrenor', 'arici', 'vin', 'veselă', 'vâna', 'umbrele', 'turele', 'torturi', 'toc', 'sare', 'republica', 'paria', 'somn', 'post', 'sol', 'poartă', 'ochi', 'mobilă', 'mie', 'formă', 'corn', 'coș', 'fata', 'fila', 'folie', 'haină', 'imobil', 'curele', 'copii'])\n",
            "[('mai bun și grâul a crescut mai des și mai viguros. Acolo era toată speranța de recoltă pentru anul acesta. Avea de gând la întoarcere să treacă și pe la bostana de deasupra lacului.', 'ENG30-09328904-n'), ('înaltă de vreo 12 m și de vreo 8 m lățime a corpului principal, dar și cu o extindere laterală. În capătul ei se afla un parc cu statui din oțel ce reprezentau animale, un cerb, o căprioară, și un lac mic plin cu rațe sălbatice, o lebădă albă și mulți porumbei și pescăruși. Porumbeii erau blânzi, veneau lângă tine și-ți cugulegeau pâinea din mână. Când le aruncam mâncarea în apă era o întreagă nebunie, zbura toată păsărimea care mai', 'ENG30-09328904-n'), ('și se-auzii, Ești craiul Dragobete, Iar Dochia e maica ta Și-al Pietrei Duh tătânul Ce-n munți și-n lac în veci va sta Fiindu-le stăpânul. Uimit de-acel ecou vocal, Privi în zare roată, În lung de lac și-n lat de mal Și-un pustnic i se-arată Cu pasul mic și trupul frânt, Parcă plutind ca pana, Ca umbra unei frunze-n vânt, Cu părul, barba, geana Mai albe decât neaua-n pisc De munte iarna', 'ENG30-09328904-n'), ('Am umplut suportul umbrelei cu apă din lac și am instalat umbrela în dreptul pescăriței, astfel ca nimic să nu o deranjeze de la ocupația care-i captivase atenția. Eu mă feream de razele soarelui cu pălăria din pai, nelipsită din arsenalul uneltelor mele de pescuit. Miruna scotea pește după', 'ENG30-09328904-n'), ('las fecioare măcar pentr-o noapte că le vrea pe toate. Apare Luna, mândră cununa, lacul când privește apa strălucește. Chip de fecioară oglindește, bietul păcat mi-l amețește. Lacom, sărmanul, nu mai gândește. Păcat nespălat Sare, despuiat, în apă de lac, unde a crăpat. Lumea a scăpat de acel păcat ce-i mult criticat și cu greu iertat. Păcat de iubire, profundă trăire, ce vine în tine, om drag, cu plăcere, îți pleacă, din brațe, lăsând doar durere. Referință Bibliografică: Păcat', 'ENG30-09328904-n'), ('din 12 aprilie 2012 Toate Articolele Autorului Orbecăind, am rătăcit neștiutor pe cărările pline de neprevăzut, rănindu-mi picioarele prin rugi și prin bolovănișuri, plângând în arșiță ori în colțuri de stânci pustiite. Mi-am spălat durerea în tulbure apă de lac ori de râu, în stropii de ploaie pe care-i priveam îndelung cum lunecă-n tremurul firavelor frunze sau fire de iarbă, fără să-mi fi văzut vreodată chipul ori culoarea ochilor. Ajuns undeva, fără să știu unde sunt, cu', 'ENG30-09328904-n'), ('care trăiesc și astăzi prin aceste locuri, mândrindu-se cu numele de comăneșteni, urmași a lui Comanus cel Bun. Timpul a trecut, dar amintirea Tarnitei a rămas vie în aceste locuri și, de veți urca pe munte, veți găsi un lac al cărui fund n-a fost atins de nimeni și care poartă numele de Tarnița. Leonid IACOB Comănești, 5 august 2014 N.B. Această povestire este o creație personală. A fost scrisă folosindu-mă doar de toponimul geografic \"Tarnița\" existent în', 'ENG30-09328904-n'), (\"vechi flașnetar, nuferii luminează ca și-o aură de îngeri și Luna se-ndrăgostește de tristul-lăutar. În bătaia Lunii, nuferii parcă-s corăbieri ce plutesc pe luciul lacului făr' de hotar, iar Luna-nfrigurată promite din răsputeri că mâine noapte, pe lac va fi iarăși, star.\", 'ENG30-09328904-n'), ('un alt cer înstelat. Parcă scotocind prin amintiri, Karon închise ochii, dar numai o clipă, pentru a-și aminti de locul acela. Era lacul unde...și se opri. Nu mai avea rost să-și amintească.', 'ENG30-09328904-n'), ('Festivalul \"Leș Films de Cannes à Bucarest\" 2016 Regizorul francez Alain Guiraudie, renumit pentru thriller-ul erotic L’Inconnu du lac, este invitatul special al festivalului Leș Films de Cannes à Bucarest (14 - 23 octombrie). Cineastul își va prezenta noul film, Rester Vertical, considerat de presa internațională filmul-șoc al ediției de anul acesta a Festivalului de la Cannes. El se alătură celorlalți', 'ENG30-09328904-n'), ('De fapt acum a rămas doar urmă de lac. Mai apăreau în albia lui câteva locuri cu mocirlă, unde mai orăcăia din când în când câte o broască răgușită. Restul de broaște stăteau ascunse prin rogozul crescut pe lângă maluri, să se ferească de căldura verii. Ajuns la bostană se', 'ENG30-09328904-n'), ('Dar dacă avea dreptate , lângă lac trebuia să fie ruinele vechii fortărețe ,și putea acolo să înnopteze iar cand zorii zilei vor veni,va avea un plan pentru ce vă urma.Nu se putea lăsa doborâta Astfel, încerca să înainteze dar atunci văzu în semi-umbră pe', 'ENG30-09328904-n'), ('Domnului Iisus Hristos, ei trecuseră de acest eveniment cu o săptămână mai devreme. La capătul salbei celor patru lacuri se ridica un baraj peste care se putea trece cu piciorul.', 'ENG30-09328904-n'), ('Diferența de nivel de la apa fiordului și cea a ultimului lac era de vreo șase metri.', 'ENG30-09328904-n'), ('păr, fără de știre, un caier au furat din miez de noapte, fir lung au tors și împletind în șoapte din stele-au strâns puțină strălucire. În iris ți-au pus verde-n tonuri blânde, dar și mister dintr-un străfund de lac, drept gene sunt doi fluturi ce-și desfac aripile cu gesturi tremurânde. În suflet ți-au sădit piersici în floare și-au cuibărit în ei un pitpalac ce cântă ne-ncetat, privind buimac cum din nimic știi să zidești altare. Din', 'ENG30-09328904-n'), ('mult mi-aș fi dorit, să-l știu, Așa cum și-n octombrie tu mi-ai zâmbit... Erai atâta de frumoasă și eu atât de fericit, Chiar dacă ploaia măruntă și rece, Ne-a cam surprins, ținându-ne de mână, Pe mal de lac, care părea, puțin mai supărat, Lăsându-se, de vânt și ploaie mângâiat, Valuri, ale sale, urcându-se ca să te vadă, Cât de frumoasă ești, în asta toamnă. Noiembrie, începe cu frig, afară și în viața mea, De ceva vreme, ai', 'ENG30-09328904-n'), ('Acasa &gt; Stihuri &gt; Semne &gt; EREZIA RACULUI DE DIAMANT Autor: Costel Zăgan Publicat în: Ediția nr. 1306 din 29 iulie 2014 Toate Articolele Autorului Salt înainte din lac în puț Moartea ne vânează pe toți Cu toate că sun tem visul unui nebun Logica socială ne urmărește și-n pat Și ca să spun așa Economia de piață este și ea aca să Totuși cel mai bine se vând oche larii', 'ENG30-09328904-n'), ('cea cu cartofii. Odată am fost duși la udat plantații de cartofi cu găleata, undeva într-o comună din apropierea capitalei. Era secetă mare în anul acela. Am fost înzestrați cu zeci de găleți, trebuia să facem un șir indian de la lac și până la tarlaua cu cartofi. Gălețile cu apă circulau într-un sens, cele goale circulau în sens invers. Părea o treabă frumoasă, bine organizată, să vezi cum băieții și fetele se întreceau cu căldările de apă în șir indian. Iar', 'ENG30-09328904-n'), ('de știre,Dar să te uit îmi pare imposibil.... VI. PLANETA OAC, de Nicolaie Dincă , publicat în Ediția nr. 2279 din 28 martie 2017. Planeta Oac de Nicolaie Tony DINCĂ Într-o noapte liniștită, Pe un plaur tolănită, În mijlocul unui lac, O broscuță năzdrăvană Își cânta, ca o soprană, Aria în nota... oac. Deodată, văzu surprinsă, Pe lacul ‒ oglindă-ntinsă, Toată bolta înstelată Și, nedumirindu-se, Se prinse gândindu-se Că lumea e răsturnată. „ Doamne, cât am fost de proastă! Ceru', 'ENG30-09328904-n'), ('firului, opoziția era puternică. Trăgeam cu putere de lansetă și mulinam în același timp. Peștele se lăsa greu convins să vină liniștit spre mal. Am slăbit un pic frâna, ca el să-și ia fir și să se plimbe pe lac până obosește, în timp ce eu mulinam, iar el, aflat în opoziție totală cu mine, trăgând spre larg, spre stuful de pe celălalt mal, eu mai conciliant spre malul opus, ne-am luptat unul cu celălalt timp de vreo cincisprezece minute, până am', 'ENG30-09328904-n'), ('anul 2009 prin fizicianul Stephen Hawking, a înclinat să dea crezare unei atare teorii. Chiar Darwin expusese o opinie similară vizavi de ipoteza panspermiei - extrem de voalat totuși -, atunci când, în ultimul paragraf al Originii Speciilor (1859), remarca faptul că „într-un lac călduț, în care se aflau toate felurile de amoniac și de săruri fosforice, lumină, căldură și electricitate” intervenea suflul divin, cu valențele chimice necesare apariției vieții.', 'ENG30-09328904-n'), ('cu turma la păscut Din zori și până-n seară Pe-un colț de rai necunoscut Din minunata-i țară. Poieni cu flori de paradis Înmiresmate-n rouă Mirifice i s-au deschis Spre altă lume, nouă. Vrăjită pe un mal de lac, Vrând turma să-și adape, La umbră de bătrân copac Se cufundă sub pleoape... Cu luna-n apa de cleștar, Pe pat de flori și iarbă, Dormea adânc cu suflul rar Și un surâs pe barbă. Dar ca un abur', 'ENG30-09328904-n'), ('încă sperăm, călâii jerfind și zâmbet și neam ? Și ranele-mi dor și obida mi-e grea și chiar de-o să mor asta e palmă mea ! Greșeli nepermise tot facem prin veac, cădem tot mereu și în puț și în lac. Nevolnici rămânem, mereu mămăligi prea moi ca să facem mai mult de un ... plici! Prea stăm așteptând că pară să cadă în guri mult prea multe căscate degeaba, cu mâinile-n sân oftând că ne doare în știu eu ce cot', 'ENG30-09328904-n'), ('pământ mai bun și grâul a crescut mai des și mai viguros. Acolo era toată speranța de recoltă pe anul acesta. Avea de gând la întoarcere să treacă pe la bostana de deasupra lacului. De fapt acum a rămas doar urmă de lac. Mai apăreau în albia lui câteva locuri cu mocirlă, unde mai orăcăia din când în când câte o broască răgușită. Restul de broaște stăteau ascunse prin rogozul crescut pe lângă maluri să se ferească de căldura verii. Ajuns la bostană se', 'ENG30-09328904-n'), ('era albumul cu fotografii de familie. După o mică ezitare, Carmen deschise albumul și privi prima poză.Un băiețel de aproape trei anișori,ținea în mână o minge. Era îmbrăcat într-un costum de marinar, șosete albe și pantofiori negri de lac. Părul blond cenușiu, cârlionțat cădea de sub bonetă.Îi râdea privirea.. Lacrimile parcă o ardeau. Șterse ochii și deschise albumul la ultima poză. Inima îi bubuia gata să-i iasă din piept. Tresări. Pe masă era un tort cu cinci lumânări', 'ENG30-04159545-n'), ('și lună,cu tine împart clipeleunui anotimp răsfiratîn fir gros din păr,tras din soare...... VII. TOAMNA..., de Cristina Mariana Bălășoiu , publicat în Ediția nr. 2097 din 27 septembrie 2016. Toamna... în asfaltul răcit bine se aud tocuri. În pantofi de lac, negrii flecurile cântă rapsodii în re-major și re-minor. Vântul frunza-n foșnet o adie și părul mi-l despică. Pământul ca un magnet atrage covor multicolor de frunze. Toamna... ciorile creionează cerul în puncte negre. Sinistru se aude o rapsodie', 'ENG30-04159545-n'), ('niciodată o femeie frumoasă, dar gătată și aranjtă avea o strălucire aparte.Îi ajungea abia până la umăr, acum șoldurile i se împliniseră, era mai rotunjoară, dar nicidecum grasă. Îmbrăcase un costum gri-petrol, își pusese ciorapi cu dungă și pantofii negrii, de lac,pe care îi asortase cu o mică poșetă ce o ținea elegant pe antebrațul mâinii stângi. Un șal împletit de ea,din fire de lână de merinos luate de la o țigancă cetrecea din când în când pe stradă cu tot', 'ENG30-04159545-n'), ('în stol. Vin și brotacii săltăreți Sub florile de castraveți, Se pregătesc de festival C-un cântec nou, original. Se-aleargă razele pe jos; În umbra teiului stufos Pășește-un țap cu ochi de drac, În frac și în bocanci de lac. Privește lumea ca un zeu, Cu șarm de țap și cu tupeu, Apoi se-oprește pe un dâmb Și unui gând zâmbește strâmb. Răsună în salcâm: Boc! Boc! El are barbă dar și cioc, Își umflă mușchii de pe piept Să', 'ENG30-04159545-n'), ('mamei și scurtată pe măsura ei cu câteva zile înainte de concurs, știind că îi vine bine. Își atinge cu vârful degetelor părul împletit cu migală de jur-împrejurul capului, ca o coroniță, și știe că totul este în perfectă stare, de la pantofii de lac și până în vârful unghiilor. Așteaptă cuminte să-i vină rândul, fără a lăsa sunetele, luminile rampei și aglomerația să o tulbure mai mult decât emoțiile primei apariții în public. Și iat-o! Pășește în fața juriului, cu ochii strălucind de lumina', 'ENG30-04159545-n'), ('frunza de frică, suflată de vânt în culori. Pământul îmbracă haină arămie, timpul rămâne în urmă. Pleoapele ridicate-n nori în sunet de clopoțel arcuri pe retină pun. Citește mai mult Toamna...în asfaltul răcit binese aud tocuri.În pantofi de lac, negriiflecurile cântă rapsodiiîn re-major și re-minor.Vântul frunza-n foșneto adie și părul mi-l despică.Pământul ca un magnetatrage covor multicolor de frunze.• Toamna...ciorile creionează cerulîn puncte negre.Sinistru se audeo rapsodie în re-major.Vibrează frunza de frică', 'ENG30-04159545-n'), ('mai poată încerca și-a doua oară. Gaskell o să stea cu ochii în patru. Trebuia să fie ceva sigur și trebuia să fie natural. Gaskell ieși pe punte cu prezervativele. Le legase împreună și pictase pe fiecare dintre ele, cu lac de unghii, câte o singură literă, în așa fel încât pe toate laolaltă se vedea textul SOS AJUTOR SOS. Apoi se urcă pe acoperișul cabinei și le lansă în aer. Prezervativele plutiră câteva clipe, luate de vântul slab, după care începură să', 'ENG30-14991004-n'), ('descălțat și eu, mi-am așezat pantofii lângă ai săi și am intrat. Camera era pătrată, fără ferestre și, din cauza tavanului jos, părea mai mare decât trebuie să fi fost în realitate. Mirosea plăcut, a cafea proaspăt râșnită și a lac de unghii. Cam două treimi erau ocupate de un pat generos, acoperit de perne și jucării de pluș. Unde se termina patul începea o masă îngustă, împărțită riguros în două zone: una cu farfurii, ibric, ceșcuțe, borcane de șerbet, zacuscă, miere, pachete', 'ENG30-14991004-n'), ('lei, argilă, supliment nutritiv - 43 100 de lei/cutie) l gama Echinaceea (cremă antirid - 61 200 de lei, cremă hidratantă - 61 200 de lei, cremă gomage - 56 700 de lei, lapte demachiant - 55600 de lei) l gama Farmec (dizolvant pentru lac de unghii - 14 600 de lei,', 'ENG30-14991004-n'), ('conducerii. 9503.70 1. Trusa de cosmetica, constând din două flacoane ce conțin o imitație de lac de unghii, o pereche de cercei, un inel, un lanț cu medalion care se deschide', 'ENG30-14991004-n'), ('de Popi, fard de pleoape Cvinta Roială... lac de unghii Ridicați pontul... pudră compactă Pas parol... ruj Kiss, cremă de noapte Faust, spumă de baie Ghizell... spray de corp transparent, deodorant Mefistofel, feminitate Îngrijită, ruj Bonsay, șampon Spărgătorul de nuci, lac de unghii Lacul lebedelor, cremă Girafă pentru coapse, tampoane pentru sâni Girafor...” De unde apăreau toate aceste denumiri? Satanovski Îl ispitise iar. Probabil că femeia care dormise goală Între ei servise drept momeală... Cine se folosise de toate aceste sprayuri, de șampoane și', 'ENG30-14991004-n'), ('lac de unghii - 33 500 de lei, cremă depilatoare - 38 000 de lei, gel după depilare - 28 200 de lei), gama GH3 (cremă contur de ochi - 57 200 de lei, cremă hidratantă - 64800 de lei, cremă', 'ENG30-14991004-n'), ('să intre și să-mi ia câte ceva sau din astea. Avea degetele lungi și cam de fete - o secundă nu mi-am dat seama de ce arată-așa, da’ după aia mi-am dat seama un pic uimită c-avea și lac de unghii pe ele. La dracu’, m-am gândit, cu asta chiar a mers prea departe. Doar a zâmbit și mai mult, și-a tras înapoi mâna și și-a apucat-o în față cu cealaltă, fin și delicat, ca un dansator', 'ENG30-14991004-n'), ('mai comenta, fă-ți nodul și gata! Un norișor de parfum ajunse în dreptul fetiței, care începu să strănute, dar nu se ridică de pe covorașul din fața ferestrei, pe care își înșirase toate jucăriile. Razele soarelui pătrundeau prin perdeaua fină, făcând picăturile de lac din părul mamei să strălucească. - Mami, ești frumoasă ca o prințesă! - Vezi, dragă, ar trebui să fii mândru de nevasta ta! - Dar, tati, nu e frumos? - Ca un balaur, râse mama. - Nuuu, ca un prinț, zâmbi știrb Mădălina. Mama răsturnă', 'ENG30-14991004-n'), ('de către copii sau tineri pentru învățarea codului rutier și la conducere, ca amuzament. Ele sunt folosite sub supraveghere în locuri special concepute pentru exersarea conducerii. 9503.70 1. Trusa de cosmetica, constând din două flacoane ce conțin o imitație de lac de unghii, o pereche de cercei, un inel,', 'ENG30-14991004-n'), ('Și adică de ce nu ar mai folosi-o? Doar cu Dimi ar putea eventual vorbi despre aceste viziuni. În orice caz, mai bine să-i Împuie capul cu profeți, șopârle, frunze de viță și neutroni decât cu bombe făcute din lac de unghii. Într-o clipă, șopârla se desprinse de pe locul ei, se arcui și țâșni ca un fulger Într-un șanț sau În spatele lui. Dispăru. Tăios și neted. Recviemul lui Fauré se termină, iar după el urmară Dansurile polovtiene de Borodin, care', 'ENG30-14991004-n'), ('de lemn de pin sau esență de celuloza cu sulfat rezultată din industria hârtiei (poziția nr. 38.05), uleiurile de gudron de lemn (poziția nr. 38.07) și solvenții compuși anorganici (poziția nr. 38.24, în general). ... b) Dizolvant pentru lac de unghii, condiționați pentru vânzarea cu amănuntul (poziția nr. 33.04). ... 38.15. INIȚIATORI DE REACȚIE, ACCELERATORI DE REACȚIE ȘI PREPARATE CATALITICE, NEDENUMITE ȘI NECUPRINSE ÎN ALTĂ PARTE - Catalizatori pe suport: 3815.11 -- Cu nichel sau compuși de nichel că substanță activă', 'ENG30-14991004-n'), ('masaj, cremă antiacneică, șampon, balsam, loțiune capilară, loțiune pentru regenerarea părului, gomage, gel exfoliant, pudră de argilă și altele. Nu vor lipsi produsele de cosmetică decorativă: lacuri pentru unghii, rujuri,', 'ENG30-14991004-n'), ('love - 107,10 RON, Glamour Glos - 74,70 RON, Max Factor Lipfinity - 54,00 RON, VBRC gloss - 26,50 RON)), creion sprâncene (Sourcils - 90,00 RON), rimel (Mascara Glamour - 45,00 RON), rimel pentru sprâncene (Gimme Brow - 101, 70 RON), lac de unghii (La Laque Couture Yves Saint Laurent - 106,20 RON, Lancome Vernis in Love - 60,35 RON, Color Hit Sephora - 18,90 RON), dizolvant unghii (Bain dissolvant - 30,60 RON), pilă de unghii (Lime Ongle - 30,60 RON), tratament hidratare/întărire', 'ENG30-14991004-n'), ('speciale Distribuitor exclusiv în România al firmei germane „Wilde Cosmetics“, S.C. „LC Nails Cosmetics România“ (Splaiul Tudor Vladimirescu la nr. 35) oferă de câtva timp spre vânzare unghii false, materiale și aparatură specială. Oferta firmei cuprinde: unghii false (diverse modele), lac de unghii peste 100 de nuanțe, soluții tratament pentru unghii și cuticule, gel special pentru aplicat unghii false, lămpi cu raze ultraviolete, diferite modele de pile, soluții pentru degresat unghii, strasuri și alte aplicații decorative, creme pentru mâini, peeling, antiage sau exfoliante', 'ENG30-14991004-n'), ('nu clipi. Îi place la nebunie, spuse el, cu vocea groasă și tristă. Bonnie bătu din palme și se uită la Karin. Karin ridică din umeri. Fata se afundă în geanta ei cu franjuri, extrăgând de acolo o rezervă de lac de unghii, pe care o pusese bine pentru astfel de situații. Bonnie îl făcu pe Mark să se întindă pe spate și să-și abandoneze picioarele acestui proces. —Cireșiu-înghețat? Ce zici de vinețiu? Nu. Degerătură? Rămâne degerătură. Karin se așeză și urmări', 'ENG30-14991004-n'), ('pilește toate celebritățile, am murmurat „Nu, mulțumesc“. Trebuie să fi fost până peste poate de cinică s-o refuz pe Xenia, vreau să spun, eu sunt atât de dependentă de manichiură, încât mă dor unghiile dacă nu-s vopsite cu lac de unghii rozalb de la NARS. Dar știți ce? Durerea de unghii era floare la ureche în comparație cu amărăciunea care mă copleșea acum. În a patra zi, Julie m-a anunțat că mă scoate în oraș. Gemenele Vandonbilt dădeau o masă pentru strângere de', 'ENG30-14991004-n'), ('lacuri și loțiuni capilare, produse înainte și după bărbierit, produse de plajă, depilatoare, parfumuri și ape de toaletă, deodorante, produse pentru baie etc. − Alte produse: hârtie igienică, batiste de hârtie, prosoape', 'ENG30-14991004-n'), ('lui Derek, nu? Îi seamănă foarte mult. — Devon Îl cheamă. Da, e a lui Derek. Seamănă deja cu tatăl lui. Janice Întinse mâna ca să-l potolească, dar Devon, plin de avânt, o ignoră. Unghiile ei erau lungi și date cu lac de unghii transparent și ușor rozaliu. — Atunci, sunt sigură că ai auzit de cele petrecute la sală, am spus. Anume, că Linda a fost ucisă. — Mi-a zis Derek, se Încruntă ea, apoi mă măsură din ochi și adăugă cu sinceritate: Ar', 'ENG30-14991004-n'), ('lei/cutie) l gama Echinaceea (cremă antirid - 61 200 de lei, cremă hidratantă - 61 200 de lei, cremă gomage - 56 700 de lei, lapte demachiant - 55600 de lei) l gama Farmec (dizolvant pentru lac de unghii - 14 600 de lei,', 'ENG30-14991004-n'), ('fond de ten, batoane corectoare, anticearcăn, acetonă și dizolvant pentru lac de unghii, deodorante, parfumuri, produse pentru epilare, produse pentru plajă și pentru uz casnic (pentru curățenie). Unitatea va avea program de funcționare zilnic între orele 7,30 și 18, iar duminica de la 8,30 la 13. C. B. „Best Computers“ l Acum', 'ENG30-14991004-n'), ('că ești neapărat mai aproape de divinitate sau de tine însuți în locuri special destinate, sau să zicem, că poți fi deopotrivă și acolo, dar și pe un vârf de munte sau privind norii dintr-un avion sau răsturnați într-un ochi de lac din pădure. Trec, uneori, pe la biserica Sfântului Elefterie, unde am senzația de cineva acolo sus, deopotrivă cu cineva în prejma noastră, pe care am avut-o întâia dată la Vatican, la San Pietro, senzație care nu avea nimic de-a', 'ENG30-09351547-n'), ('25 Noiembrie 1968 în Botoșani, Adriana V. Neacșu și-a petrecut copilăria pe aproape de locurile unde se născuse și marele Eminescu și cred eu că, așa cum făcuse înaintașul ei ilustru, „cutreierase” acele locuri magice, văzuse și ea în acei ani „lacul codrilor” și nuferii, Ipoteștii și Agaftonul și alte minunate locuri din împrejurimi. Dar, mai ales, trăise în lumea de povești și întâmplări spuse de bunici, de cei ai casei. Imaginile acestor locuri magice, dulcea pasăre a copilărie le va duce cu', 'ENG30-09351547-n'), ('florii-albastre-un fir de păr. Din codrii ei cu arbori de sequoia O creangă el a rupt nepăsător; Ce-i pasă oare codrului de voia Ce-o duce el în sufletul de dor? Ah, floarea a simțit, și-adânc mirată Un ochi de lac albastru, nemișcat, Clipind și clipocind din geana mată Spre ciobul neguros a îndreptat. -De unde vii și cine ești, băiete, De cine ești trimis, tu, ce dorești? Cumva îți este foame, îți e sete, Ești unic printre flori, ori flutur', 'ENG30-09351547-n'), ('din viață Când remușcări tăcute dreptul lor și-l cer. Pune-n văzul lumii umila lui tarabă, Te ademenește cu vorbe ce îți plac Nu-ți privește ochii și nici nu te întreabăîn vraja lui te-afunzi ca luna-n ochi de lac. îți vinde tot ce-n viață tu n-ai putut să ai Galant, îți dă din toate, măcar câte-un pic Nu vrea bani, doar sufletu-n fărâme să i-l dai, Cu el să îi plătești că ți-a', 'ENG30-09351547-n'), ('albăstrele... în concert enescian lutul de acasă îmi poartă urmele acolo pe oriunde ... aici ochii tăi mari și adânci devin felinare contopite în cioburi de stea umbli azi hai-hui prin sufletul meu oferindu-mi șoapte din dorurile tale de ducă de lac de drag de plopi de stele... de ea... luna cea de atunci și cea de acum alunecă pe umeri de umbre se ascunde în teii care ard în neliniști și tremură ... Citește mai mult trăiesc în cea mai bunădintre lumiunde', 'ENG30-09351547-n'), ('prim plan se află zâna învăluită în șal și rochie, cu părul auriu și lung, purtând o cunună de flori, în fundal descoperim înconjurat de pădure un lac pe care plutesc lebede. Pictorul a ales închiderea naturală de rezonanță lirică, \"lacul codrilor albastru\", pentru sugestia unei intimități privilegiate și a unui farmec care-și dă măsura numai aici. Zâna respiră senzualitatea indecisă a femeilor fin de siècle, cu buzele întredeschise, cu un zâmbet misterios, cu aerul volatil propriu aparițiilor difuze sau cortegiilor', 'ENG30-09351547-n'), ('au inventat-o, n-au dobândit-o, căci o aveau în ființa lor. Locul acesta a fost sfințit de un om și este locul care smuls poezia unei vieți, unei vieți făcute pentru poezie. Ipoteștii însemnă strigătul ,,pădurii de argint”, ,,lacul codrilor albastru”, ,,văzduhul tămâiet”, basmul, luceafărul ceresc a cărui strălucire a sporit o dată mai mult cu farmecul și frumusețea plămădite de autorul acelui Luceafăr al pământului românesc, Mihai Eminescu. Un om, un nume, un simbol, o temelie pentru veacurile viitoare ale', 'ENG30-09351547-n'), ('Autor: Ionel Grecu Publicat în: Ediția nr. 1471 din 10 ianuarie 2015 Toate Articolele Autorului EMINESCU din binecuvântata Bucovină la miez de veac a răsărit lumină. e Făt-Frumos cu plete de-abanos. e fiul lirei și al melosului dulce. e lacul codrilor albaștri, cu nuferi galbeni Încărcat. a Ipoteștilor icoană de Domnul cu har înzestrat. porni Luceafărul în zori, de sus din haos ne privește. de strajă țării și neamului el este. la fiecare început de an pornim la drum cu al', 'ENG30-09351547-n'), ('se pierdu. Reveni, se spulberă iarăși și iarăși reveni, băiat bucălat și peltic. Un înger bucălat, cu zulufi, aterizat la picioarele băncii. Pantalonași de doc albastru, vestă tirolez. Ochi imenși și reci, degete scurte și roz. Copacii unduiau, clipocea lacul,', 'ENG30-09351547-n'), ('Eminescu a fost și va rămâne pentru mine, poetul de suflet, poetul ne- preche de o rară elevație pentru toată frumusețea să spirituală, pentru dragostea să nealterata față de ființă dragă inimii sale, pentru întreaga sa poezie , în care a cântat „ lacul codrilor albaștrii, freamătul pădurii cu păsări pe sub ramuri, locurile natale , universul și toată starea de spirit a poporului nostru. Pentru mine Eminescu, este intangibil, este unic, este universal . Dragostea mea nemărginita față de poezia să, față de frumusețea să stelara, am căutat să', 'ENG30-09351547-n'), ('ostrov sfințit cu lacrimile rugăciunilor Sfanțului Ierarh Calinic de la Cernica, ale Sfanțului Cuvios Gheorghe de la Cernica și ale Sfanțului Cuvios Irodion de la Lainici, lacrimi curate și multe care au curs precum izvoarele la vale până s-a umplut cu aghiasma „lacul codrilor albastru” care înconjoară acum mănăstirea cu o duioasa îmbrățișare lacustra, în acest loc sfânt, statornic intru statornicie, se nevoiește intru cele duhovnicești smeritul și preacuviosul părinte protosinghel Ignatie Grecu. Că o harfa eoliană acordată după diapazonul sferelor cerești și bătaia', 'ENG30-09351547-n'), ('sărut suspină-n ruginiu de toamnă o cană se îmbracă cu roșu de struguri amintiri strivesc buze din nopți de jăratec rătăcită o rază spre noapte aleargă spre apus cerul suspină încă lumină un eu mă alergă spre iarnă un ochi de lac închide gene printre raze târziu frigul se zgribulește-n ferestre uitate pe mine am dezbrăcate priviri un colț de umbră rătăcește tremurând câmpia zarea dincolo de mine uită ziua trecută o frântură de rouă se sparge înghețată toamna spre iarnă strigă', 'ENG30-09351547-n')]\n",
            "[('că e de mirare magistre. Acest Iisus avea un renume de tămăduitor care a ajuns până în Siria și mai departe spre nord către Edessa. Și mai spre sud asemeni spre Hebron și Idumeea ori spre răsărit dincolo de Ierihon și marele lac sărat. -Am auzit și eu Gaius despre acest Iisus încă de când eram în Ioppe și așteptam să se formeze caravana cu care am venit aici. Era acolo un om care făcea o mare operă de binefacere. Îl cunoscuse pe acest', 'ENG30-09328904-n'), ('recăsătorească. Îi plăcea foarte mult calitatea sa de divorțată. Se învârtea în sfere prea selecte ca să-și strice această stare de femeie independentă atât financiar cât mai ales social. Cunoscuse de când avea hotelul, clubul și baza nautică de agrement de pe lac, destui bărbați interesanți, de care s-a folosit în ascensiunea sa socială. Își amintea uneori cu neplăcere de începuturile sale, o fată de țară, cu o diplomă de liceu în buzunar și ăla făcut cu chiu cu vai și cu', 'ENG30-09328904-n'), ('Pe malul celălalt al lacurilor, la capătul barajului, se întindea o colină cu o perdea de conifere, iar o cărare șerpuia în pantă ascendentă printre molizi. M-am aventurat singur spre necunoscut. Nu mai era', 'ENG30-09328904-n'), ('ar fi rezolvat problema dacă ar fi știut din timp. Avuseseră însă, chiar de la ei, cu ceva timp în urmă, infomația că și-au asigurat cazarea. Nu aveau decât să-și găsească, măcar provizoriu, o gazdă. Îndrumați fiind „mai sus de lac” căutau, potrivit informațiilor primite, locuința unei femei „care crește capre” și care le-ar fi putut închiria o cameră. Fără să-și cunoască reciproc gândurile, în mintea fiecăruia stăruia povestirea pățaniei lui Nică al lui Ștefan a Petrei. Erau totuși', 'ENG30-09328904-n'), ('că-s stea?!... Oare, ce-i cu mintea mea?!... Cred că a plecat hai-hui... Eu sunt soarele-ntre stele, Cea mai... vie dintre ele- ... Citește mai mult Planeta Oacde Nicolaie Tony DINCĂÎntr-o noapte liniștită,Pe un plaur tolănită,În mijlocul unui lac, O broscuță năzdrăvanăîși cânta, ca o soprană,Aria în nota... oac.Deodată, văzu surprinsă,Pe lacul ‒ oglindă-ntinsă,Toată bolta înstelatăși, nedumirindu-se,Se prinse gândindu-seCă lumea e răsturnată.„ Doamne, cât am fost de proastă!Ceru-n jurul meu adastăIar', 'ENG30-09328904-n'), ('De aici și până la a ne imagina un lac călduț aflat în altă parte a Universului decât pe Terra noastră nu a mai fost decât un pas. Să ne imaginăm însă Pământul primordial, cu o Lună abia formată și supus unui bombardament extrem venit din spațiu. Asteroizi și comete', 'ENG30-09328904-n'), ('din 18 ianuarie 2014 Toate Articolele Autorului iubirea îi e ochi de curcubeu desprinsă din mângâierea părinților deasupra unui leagăn cu povești citea pe o scară de lemn la cinci ani despre lebede ce mergeau printre trestii la culcare pe lac punea bărcuțe pe pârâu și odată l-a întrebat o fetiță unde îi e tatăl i-a răspuns că e după gratii lângă al lui și lângă bunicu-său i-a fost de ajuns copil fiind să ucidă cu praștia o', 'ENG30-09328904-n'), ('-i o glumă, n-are chef de glume, nu vrea să se-oprească și să se consume. Nimenea nu stie ce s-a întâmplat și cum deodată luna a secat: undeva, departe, la margini de lume, s-a creat un lac cu un scop anume. Cei mai albi, la suflet, parcă și la piele, dau o fugă, zilnic, doar ca să se spele, apa-i cea din luna, nu a fost furată, Dumnezeu le-a dat-o celor buni răsplată. Aș vrea', 'ENG30-09328904-n'), ('așa de agresivi cum ne așteptam, deoarece pătura întunecată a nopții era alungată de lumina zorilor și țânțarii erau acum inofensivi. Se prefigura o zi frumoasă, chiar dacă nu era promițătoare în temperaturi ridicate și nici nu ne doream asta. Pe lac, din când în când, o broască țestoasă își scotea capul deasupra apei, în zona pâlcului de stuf. Acest lucru nu era de bun augur pentru intenția mea de a pregăti o prăjină din carbon, ușoară, de opt metri lungime, pentru ca', 'ENG30-09328904-n'), ('de aproximativ 73 milioane de euro. Palas Iasi este singurul proiect de retail din țară care are ca principală ancoră un parc. Acesta este unul dintre numeroasele puncte de atracție, amplasat pe locul grădinii fostei Curți Domnești. Parcul cuprinde un lac și foișor pentru ceremonii, iar miile de plante și sutele de arbori vor încânta ochii vizitatorilor în orice anotimp. Inedit este faptul că una dintre ieșirile pietonale din parcarea subterană duce la o insulă a lacului, pe care sunt amplasate', 'ENG30-09328904-n'), ('de preocupările sale, urmărind cu atenție evoluția plutei sau a bambinelor. Razele soarelui deveniseră supărătoare. Chiar dacă se anunțase o zi cu nebulozități, între cele două maluri înalte ale lacului Limanu era destul de cald', 'ENG30-09328904-n'), ('24 Aprilie 2017 Referință Bibliografică: LACUL CU NUFERI / Maria Ileana Tănase : Confluențe Literare, ISSN 2359-7593, Ediția nr. 2355, Anul VII, 12 iunie 2017. Drepturi de Autor: Copyright © 2017 Maria Ileana Tănase : Toate Drepturile Rezervate. Utilizarea integrală', 'ENG30-09328904-n'), ('pe un trunchi de copac de pe malul apei. Un pescar își încerca norocul sau își petrecea pur și simplu timpul pescuind printre tufe de plante acvatice, bucuros că Dumnezeu i-a adus delta aici în inima pădurii. Astfel, un colțișor de lac, de o limpezime incredibilă, ne-a oferit o imagine de o claritate aproape nepământească a unui colț de cer albastru presărat de un nor alb, care îți captiva privirea însenind-o. Era o reflectare atât de clară și atât de profundă', 'ENG30-09328904-n'), ('îngrop în tomuri senzuale. Mă cațăr pe ochii nimicului din lume spre a observa cu ocheane de carton solitudinea. Petalele vocilor mefistotelice joacă poker cu bastioanele țesălate de zmei. Ce șaradă cuneiformă e viața! Umbrele sensurilor mele își pun pantofii de lac și încep să facă conexiunea între mine și Styx. Oamenii mimează încontinuu grimase ticăloase și false. Timpii morți incinerează norocul din lume. Ce șaradă larvară e viața ! Ce sexofilică e și moartea! Crăcișorii leagănului pensat de absurdul din carnea mea', 'ENG30-04159545-n'), ('Acasa &gt; Poezie &gt; Vremuri &gt; TOAMNA... Autor: Cristina Mariana Bălășoiu Publicat în: Ediția nr. 2097 din 27 septembrie 2016 Toate Articolele Autorului Toamna... în asfaltul răcit bine se aud tocuri. În pantofi de lac, negrii flecurile cântă rapsodii în re-major și re-minor. Vântul frunza-n foșnet o adie și părul mi-l despică. Pământul ca un magnet atrage covor multicolor de frunze. • Toamna... ciorile creionează cerul în puncte negre. Sinistru se aude o rapsodie', 'ENG30-04159545-n'), ('-și palma peste fruntea mea de frig, peste fruntea mea de urâtă, dar acolo nu era nimeni, doar șirul prelung de spaime și mâinile mici, strângându-se deasupra capului, să nu mă lovească din nou piciorul acela cu pantof de lac și mâna aceea sub formă de gheară ...și depărtarea care durea când mama mea dispărea în colbul drumului, ducând cu ea parfumul de mere și mângâierea pe care nici nu mai știu dacă mi-a dat-o cândva, lăsându-mi', 'ENG30-04159545-n'), ('spus o poezioară. Ce i-oi fi spus, nu știu. Mi s-a povestit mai târziu că m-am oprit din tremurat și din plâns, în momentul în care, de sub mantia lungă și roșie a Moșului, am zărit pantofii negri de lac ai bunicului... Pentru familia mea Câmpeni-ul era un loc minunat, cu multă liniște și aer curat. Oamenii de aici erau cinstiți, aveau o demnitate cu care se puteau mândri. Moții nu puteau fi călcați în picioare. Părinții găsiseră aici', 'ENG30-04159545-n'), ('ceai (12 pers.) - 569000 de lei, farfurii porțelan - 18 000-27 000 de lei/buc. l MAGAZINUL „GABRIELA“ (Centrul Comercial „Terra“, stand E1) vinde produse cosmetice, marca „Revlon“: rujuri - 230 000-328 000 de lei, fond de ten - 303 000-467000 de lei, lac de unghii - 215 000 de lei, pudre - 540000 de lei, rimel - 180000-335 000 de lei, fard de ochi - 230 000-335 000 de lei, fard de obraz - 504 000 de lei. ( M. D. P.) depozite S.C. „Bledea Impex“ S.R.L. vinde en gros, prin intermediul', 'ENG30-14991004-n'), ('an care trece nu a fost cel mai bun pentru economia globală, dar acest lucru nu i-a oprit pe unii patroni de restaurante sau producători să ceară prețuri foarte mari pentru anumite produse. Designerul de bijuterii Azature produce un lac de unghii care are în componență și praf de diamante. Prețul? 250.000 de dolari, scrie publicația Huffington Post, scrie economica.net. 120 de milioane de dolari s-au plătit în luna februarie a acestui an pentru tabolul Strigatul al lui Edvard', 'ENG30-14991004-n'), ('agrafe de păr, bigudiuri, cântare de persoane și de bebeluși etc. − Articole pentru igiena personală: săpun de toaletă, săpun medicinal, ulei și lapte demachiant, săpun de bărbierit, cremă și spumă de bărbierit, pastă de dinți etc. − Produse de frumusețe: ruj, lac de unghii, farduri și produse de demachiere (inclusiv pudriere și pufuri),', 'ENG30-14991004-n'), ('pentru viața de apoi. Prin urmare, acolo nu se poate fără adjuvante, nu-i așa? Simțurile dispar. Gustul, văzul și auzul. Dar pipăitul și mirosul? „Rimel Plumb Aut Mascara, luciu de buze Full de Popi, fard de pleoape Cvinta Roială... lac de unghii Ridicați pontul... pudră compactă Pas parol... ruj Kiss, cremă de noapte Faust, spumă de baie Ghizell... spray de corp transparent, deodorant Mefistofel, feminitate Îngrijită, ruj Bonsay, șampon Spărgătorul de nuci, lac de unghii Lacul lebedelor, cremă Girafă pentru coapse, tampoane', 'ENG30-14991004-n'), ('în 4-5 zile. Este momentul să mutăm „ghiveciuțul“ într-un loc însorit. Să nu uităm să-l udăm. Când iarba este destul de mare, se aranjează „freza“ cu o forfecuță. Ouăle golite se pot colora cu tempera, acuarele, carioca, rămășițe de lac de unghii. Pe ele se pot lipi mărgeluțe, bucăți de hârtie colorată sau staniol, resturi de lână multicolore. Sau se pot tăvăli prin semințe de mac. Totul e să vă folosiți imaginația. Se poate face un „copac cu ouă“, atârnând ouăle decorate', 'ENG30-14991004-n'), ('lac de unghii - 33 500 de lei, cremă depilatoare - 38 000 de lei, gel după depilare - 28 200 de lei), gama GH3 (cremă contur de ochi - 57 200 de lei, cremă hidratantă - 64800 de lei, cremă de față - 59300 de lei, loțiune regeneratoare', 'ENG30-14991004-n'), ('un lanț cu medalion care se deschide și în care încape unul din flacoanele cu lac de unghii. Ansamblul este din material plastic (cu exceptia lanțului care este din metal), condiționat pentru vânzarea cu amănuntul', 'ENG30-14991004-n'), ('și în care încape unul din flacoanele cu lac de unghii. Ansamblul este din material plastic (cu exceptia lanțului care este din metal), condiționat pentru vânzarea cu amănuntul într-o cutie de carton și este pentru amuzament. Aplicare a RGI 1 și 6. 9503.70 2. Set pentru topirea și modelarea ciocolatei', 'ENG30-14991004-n'), ('1 buc. 10 240. C240 Cosmetice 241. C241 - Apa de colonie 100 ml 10 242. C242 - Apa de gură 100 ml 3 243. C243 - Cremă de mâini 100 ml 2 244. C244 - Depilator 100 ml 2 245. C245 - Dizolvant pentru lac de unghii 200 ml 1 246. C246 - Pastă de dinți 100 ml 2 247. C247 - Produs de curățat proteze dentare 200 ml 1 248. C248 - Pudra de talc 300 g 1 249. C249 - Spumant de baie 250 g 1 250. C250 - Șampon', 'ENG30-14991004-n'), ('din gamele: „Farmec Echinaceea“, „Gerovital Plant“, „Gerovital H3“, „Farmec“ pe bază de gălbenele, mușețel, aloe vera și gama „Aslavital“ cu produse pe bază de argilă. De asemenea, sunt expuse deodorante pentru femei și bărbați, produse pentru machiaj „Gerovital Plant“ și lac de unghii. C. B. Lucrări de tâmplărie PVC l Cu geam termopan pentru ferestre sau uși S.C. „Tekin“ S.R.L. a deschis recent un nou magazin de prezentare, amplasat în complexul din sensul giratoriu ce unește Calea Șagului cu Bd. I. Maniu. Aici', 'ENG30-14991004-n'), ('toată ziua pentru mine... PIANISTA: Trebuie s-o întindem. Nu mai trebuie să avem nevoie de noi de acum încolo. O să spun ceva de nimic: Mâncarea e gata Vremea e frumoasă Se colorează, Fiecare timpan îmbătrânește Acum producem din nou lac de unghii cu nasturi COMPOZITORUL (se lipește resemnat de ea): Să se fixeze toate pionezele acum inundăm din nou haznaua pâinea zilnică mirosul muncii făcut pe drept pe lângă noi nu se mai strecoară zilnica lume a zilei și ca locuri istorice există', 'ENG30-14991004-n'), ('Mircea Eliade, Aron Cotruș, Mihai Eminescu), busturi în bronz executate de binecunoscutul și regretatul sculptor Nicăpetre. Undeva, puțin mai departe, se zărește un lac, cu trestii, nuferi și o insulă plutitoare (totul amintește de Eminescu și de inegalabilele lui versuri ,,lacul codrilor albaștri/ nuferi galbeni îl încarcă/ tresărind în cercuri albe/ el cutremură o barcă’’ - Lacul). Peste el trece o punte îngustă de lemn, la capătul căreia urci câteva trepte ca să ajungi la o bisericuță făcută tot din lemn, unde la ora', 'ENG30-09351547-n'), ('A lăsat poezii ce alții nu pot întrece, “Luceafărul” e printre stele și de sus privește, Dorul lui cel mare și scrisorile umbrite, Ne amintesc de un om care a crezut prea mult în vise. Ne-a lăsat “dorința” în “lacul codrilor albastru” Și o poveste în versuri, Călin cel măiastru, Care n-a pierit nici azi, toți școlarii îl citesc, Iar poetul nostru va dăinui aici pe veci. E scris in stele să îl slăvim pe el, Un mare poet care', 'ENG30-09351547-n'), ('lacul codrilor albaștri, liliacul înflorit și privighetorile Edenului în care mișunau santinele și țiuiau antenele iscoadelor și se lățea, victorioasă, puterea subteranei. Privea fermecat plicul lucios, scrisoarea. Trase plicul, trase spre sine, de la capătul băncii, plicul și scrisoarea trecutului. Le privi, o', 'ENG30-09351547-n'), ('se ceartă cu serafi uituci care pun în mâncare pătrunjel celest și cimbrișor din grădina lui tezeu unde erau sunete moi acum este o întunecoasă absență trec prin noi grețuri romantice cu femei fatale frumoase cu pulpe de abanos cu ochi de lac adânc cu glezne colilie cu mers de căprioare se arcuiesc cu șoldurile doldora de plăceri niște hiene care își adulmecă prada până o căpiază și apoi o înghit fără s-o mai îngurciteze cu gurile lor flămânde noi fumăm pipă', 'ENG30-09351547-n'), ('viitor. De nu mai apare speranța la orizont, EMINESCU SĂ NE JUDECE! Când simțim că nu mai avem modele, EMINESCU SĂ NE JUDECE. Când ni se pare că s-au închis potecile afirmărilor, când totu-i gri, când pare că lacul codrilor albastru a secat, EMINESCU SĂ NE JUDECE. De judecata aspră a genialității lui s-avem parte și-atunci când îl renegăm, nu-l citim, ori nu-l cunoaștem, căci Eminescu este idolul incontestabil al tuturor și totuși prea puțin îl cunosc', 'ENG30-09351547-n'), ('căsuță în Botoșani și un bordei, acoperit pînă acum cîțiva ani cu stuf, în Liveni, lîngă Dorohoi. Ceva mai \"încropit\" a fost Eminescu; la Ipotești avea un domeniu, casă mare și un lac în pădure (căruia i s-a spus \"lacul codrilor albastru\"), cu nuferi, barcă, lebădă... Otilia Cazimir are, și ea, o căsuță pitită într-o mahala ieșeană căreia i se spune Beilic. Casa de la Haimanale, lîngă Ploiești, a familiei Caragiale nu mai e. în schimb, Vasile Alecsandri are un conac', 'ENG30-09351547-n'), ('calendar, anotimpuri și vârste, Eminescu este steaua noastră solară. Sub aburul versurilor eminesciene, totul arată mai nobil, mai sincer și mai frumos; îl caută poeții și îl iubesc îndrăgostiții de pretutindeni, natura freamătă „la mijloc de codru des” sau pe „lacul codrilor albastru” și se limpezesc aștrii și „scapără”, copiii se copilăresc și bătrânii se înțelepțesc. Rodica Elenă LUPU Ianuarie 2011 Referință Bibliografica: Luceafărul poeziei românești / Rodica Elenă Lupu : Confluente Literare, ISSN 2359-7593, Ediția nr. 41, Anul I, 10 februarie 2011. Drepturi', 'ENG30-09351547-n')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functiile responsabile cu feature extraction**"
      ],
      "metadata": {
        "id": "7FPUFqR8J5h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "import rowordnet as rwn\n",
        "from nltk.classify import MaxentClassifier\n",
        "\n",
        "vec = DictVectorizer()\n",
        "wn = rwn.RoWordNet()\n",
        "nlp = spacy.load(\"ro_core_news_lg\")\n",
        "\n",
        "# extragerea hipernimelor\n",
        "def extract_hypernymes(word):\n",
        "    hyper = []\n",
        "    synset_ids = wn.synsets(literal=word.lemma_, pos=rwn.synset.Synset.Pos.NOUN)\n",
        "    if len(synset_ids) > 0:\n",
        "        c = wn.synset_to_hypernym_root(synset_ids[0])\n",
        "        for c1 in c:\n",
        "            if len(wn(c1).literals):\n",
        "                hyper.append(wn(c1).literals[0])\n",
        "    hyper_dict = {}\n",
        "    l = 5 if len(hyper)>2 else len(hyper)\n",
        "    for i in range(len(hyper)):\n",
        "      hyper_dict[\"hyper\"+str(i)] = hyper[i]\n",
        "\n",
        "    return hyper_dict\n",
        "\n",
        "# functie care creaza pentru fiecare cuvant un dictionar de trasaturi, continand \n",
        "# informatii legate de morfologia (lemma, morpho), sintaxa(pos, dep) si\n",
        "# sensul(hyper) cuvantului\n",
        "def extract_feat_for_word(word, rel):\n",
        "    hyper = {}\n",
        "    if word.pos_ == \"NOUN\":\n",
        "        hyper = extract_hypernymes(word)\n",
        "    morph = word.morph.to_dict()\n",
        "    d = {\n",
        "        (\"text\"+rel): word.text,\n",
        "        \"pos\"+rel: word.pos_,\n",
        "        \"lemma\"+rel: word.lemma_,\n",
        "        \"dep\"+rel: word.dep_,\n",
        "         \"ner\"+rel: word.ent_type_,\n",
        "    }\n",
        "    d.update(morph)\n",
        "    d.update(hyper)\n",
        "    return d\n",
        "\n",
        "# pentru a cuprind si informatia contextuala, se creaza dictionar de features nu doar pt cuvantul target cat si pentru cuvintele din propozitie \n",
        "# cu care se afla in relatie sintactica\n",
        "def create_features_vector(word, context):\n",
        "    text = nlp(context)\n",
        "    vect = {}\n",
        "    for w in text:\n",
        "      if w.lemma_ == word:\n",
        "            if w.head != w:\n",
        "              vect.update(extract_feat_for_word(w.head, \"head\"))\n",
        "              for ind, siblings in enumerate(w.head.children):\n",
        "                vect.update(extract_feat_for_word(siblings, \"0_\"+str(ind) if w != siblings else \"main\"))\n",
        "            else:\n",
        "              vect.update(extract_feat_for_word(w, \"main\"))\n",
        "            for chil in w.children:\n",
        "              vect.update(extract_feat_for_word(chil, \"children\"))\n",
        "        \n",
        "    return vect\n",
        "\n",
        "# functie care aplica tehnicile de feature extraction pe datele de intrare\n",
        "def prepare_data(data):\n",
        "  new_data_per_words = {}\n",
        "\n",
        "  for word, instances in data.items():\n",
        "    sense = word\n",
        "    new_data = []\n",
        "    \n",
        "    for i in instances:\n",
        "      new_data.append((create_features_vector(sense,i[0]), i[1]))\n",
        "    new_data_per_words[word] = new_data\n",
        "\n",
        "\n",
        "  return new_data_per_words\n",
        "\n",
        "a = prepare_data(train_data)\n",
        "b = prepare_data(test_data)\n",
        "\n",
        "print(a.keys())\n",
        "print(b['lac'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbEIQ-KXXKGj",
        "outputId": "a859cc13-eb92-4906-bba2-51177ee8fe8c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['lac', 'lin', 'mare', 'masa', 'opus', 'pană', 'păr', 'para', 'nouă', 'bancă', 'broască', 'călca', 'car', 'colonie', 'consola', 'casa', 'accident', 'acru', 'alpaca', 'abate', 'anticar', 'vin', 'veselă', 'vâna', 'umbrele', 'turele', 'torturi', 'toc', 'sare', 'republica', 'paria', 'somn', 'post', 'sol', 'poartă', 'ochi', 'mobilă', 'mie', 'formă', 'corn', 'fata', 'imobil'])\n",
            "[({'texthead': 'sud', 'poshead': 'NOUN', 'lemmahead': 'sud', 'dephead': 'ROOT', 'nerhead': '', 'Definite': 'Ind', 'Gender': 'Masc', 'Number': 'Sing', 'hyper0': 'lac', 'hyper1': 'cardinal', 'hyper2': 'direcție', 'hyper3': 'așezare', 'hyper4': 'legătură', 'hyper5': 'abstractizare', 'hyper6': 'entitate', 'text0_0': 'Și', 'pos0_0': 'CCONJ', 'lemma0_0': 'și', 'dep0_0': 'cc', 'ner0_0': '', 'Polarity': 'Pos', 'text0_1': 'mai', 'pos0_1': 'ADV', 'lemma0_1': 'mai', 'dep0_1': 'advmod', 'ner0_1': '', 'text0_2': 'spre', 'pos0_2': 'ADP', 'lemma0_2': 'spre', 'dep0_2': 'case', 'ner0_2': '', 'AdpType': 'Prep', 'Case': 'Acc,Nom', 'text0_3': 'asemeni', 'pos0_3': 'ADV', 'lemma0_3': 'asemeni', 'dep0_3': 'amod', 'ner0_3': '', 'Degree': 'Pos', 'text0_4': 'Hebron', 'pos0_4': 'PROPN', 'lemma0_4': 'Hebron', 'dep0_4': 'nmod', 'ner0_4': 'GPE', 'text0_5': 'răsărit', 'pos0_5': 'NOUN', 'lemma0_5': 'răsărit', 'dep0_5': 'conj', 'ner0_5': '', 'text0_6': 'Ierihon', 'pos0_6': 'PROPN', 'lemma0_6': 'Ierihon', 'dep0_6': 'nmod', 'ner0_6': 'GPE', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'conj', 'nermain': 'LOC', 'text0_8': '.', 'pos0_8': 'PUNCT', 'lemma0_8': '.', 'dep0_8': 'punct', 'ner0_8': '', 'textchildren': 'sărat', 'poschildren': 'ADJ', 'lemmachildren': 'sărat', 'depchildren': 'amod', 'nerchildren': 'LOC'}, 'ENG30-09328904-n'), ({'texthead': 'baza', 'poshead': 'NOUN', 'lemmahead': 'bază', 'dephead': 'conj', 'nerhead': '', 'Case': 'Acc', 'Definite': 'Ind', 'Gender': 'Masc', 'Number': 'Sing', 'hyper0': 'lac', 'hyper1': 'plimbare_pe_jos', 'hyper2': 'călătorie', 'hyper3': 'deplasare', 'hyper4': 'modificare', 'hyper5': 'acțiune', 'text0_0': 'și', 'pos0_0': 'CCONJ', 'lemma0_0': 'și', 'dep0_0': 'cc', 'ner0_0': '', 'Polarity': 'Pos', 'text0_1': 'nautică', 'pos0_1': 'ADJ', 'lemma0_1': 'nautic', 'dep0_1': 'amod', 'ner0_1': '', 'Degree': 'Pos', 'text0_2': 'agrement', 'pos0_2': 'NOUN', 'lemma0_2': 'agrement', 'dep0_2': 'nmod', 'ner0_2': '', 'hyper6': 'faptă', 'hyper7': 'event', 'hyper8': 'trăsătură_psihologică', 'hyper9': 'abstractizare', 'hyper10': 'entitate', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nmod', 'nermain': '', 'textchildren': 'de', 'poschildren': 'ADP', 'lemmachildren': 'de', 'depchildren': 'case', 'nerchildren': '', 'AdpType': 'Prep'}, 'ENG30-09328904-n'), ({}, 'ENG30-09328904-n'), ({'texthead': 'Îndrumați', 'poshead': 'VERB', 'lemmahead': 'îndruma', 'dephead': 'ROOT', 'nerhead': '', 'Mood': 'Ind', 'Number': 'Plur', 'Person': '3', 'Tense': 'Imp', 'VerbForm': 'Ger', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'obj', 'nermain': '', 'Definite': 'Ind', 'Gender': 'Masc', 'hyper0': 'lac', 'text0_1': 'căutau', 'pos0_1': 'VERB', 'lemma0_1': 'căuta', 'dep0_1': 'parataxis', 'ner0_1': '', 'text0_2': '.', 'pos0_2': 'PUNCT', 'lemma0_2': '.', 'dep0_2': 'punct', 'ner0_2': '', 'textchildren': '”', 'poschildren': 'PUNCT', 'lemmachildren': '”', 'depchildren': 'punct', 'nerchildren': '', 'Degree': 'Pos', 'AdpType': 'Prep', 'Case': 'Acc'}, 'ENG30-09328904-n'), ({'texthead': 'prinse', 'poshead': 'VERB', 'lemmahead': 'prinde', 'dephead': 'parataxis', 'nerhead': '', 'Case': 'Acc,Nom', 'Definite': 'Def', 'Gender': 'Fem', 'Number': 'Sing', 'hyper0': 'boltă_cerească', 'hyper1': 'suprafață', 'hyper2': 'frontieră', 'hyper3': 'extremitate', 'hyper4': 'parte', 'hyper5': 'loc', 'textmain': 'lacul', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'obl', 'nermain': '', 'text0_1': ',', 'pos0_1': 'PUNCT', 'lemma0_1': ',', 'dep0_1': 'punct', 'ner0_1': '', 'textchildren': ',', 'poschildren': 'PUNCT', 'lemmachildren': ',', 'depchildren': 'punct', 'nerchildren': '', 'PronType': 'Prs', 'Mood': 'Ind', 'Person': '1', 'Tense': 'Pres', 'VerbForm': 'Fin', 'text0_0': ',', 'pos0_0': 'PUNCT', 'lemma0_0': ',', 'dep0_0': 'punct', 'ner0_0': '', 'text0_2': 'Se', 'pos0_2': 'PRON', 'lemma0_2': 'sine', 'dep0_2': 'expl:pass', 'ner0_2': '', 'Reflex': 'Yes', 'Strength': 'Weak', 'text0_3': 'gândindu-seCă', 'pos0_3': 'NOUN', 'lemma0_3': 'gândindu-seCă', 'dep0_3': 'nsubj:pass', 'ner0_3': '', 'text0_4': 'lumea', 'pos0_4': 'NOUN', 'lemma0_4': 'lume', 'dep0_4': 'nsubj:pass', 'ner0_4': '', 'hyper6': 'lucru', 'AdpType': 'Prep', 'Number[psor]': 'Plur', 'Poss': 'Yes'}, 'ENG30-09328904-n'), ({'texthead': 'imagina', 'poshead': 'VERB', 'lemmahead': 'imagina', 'dephead': 'conj', 'nerhead': '', 'Tense': 'Pres', 'VerbForm': 'Part', 'text0_0': 'și', 'pos0_0': 'CCONJ', 'lemma0_0': 'și', 'dep0_0': 'cc', 'ner0_0': '', 'Polarity': 'Pos', 'text0_1': 'până', 'pos0_1': 'ADP', 'lemma0_1': 'până', 'dep0_1': 'mark', 'ner0_1': '', 'AdpType': 'Prep', 'Case': 'Acc,Nom', 'text0_2': 'a', 'pos0_2': 'PART', 'lemma0_2': 'a', 'dep0_2': 'mark', 'ner0_2': '', 'PartType': 'Inf', 'text0_3': 'ne', 'pos0_3': 'PRON', 'lemma0_3': 'eu', 'dep0_3': 'iobj', 'ner0_3': '', 'Number': 'Sing', 'Person': '1', 'PronType': 'Ind', 'Strength': 'Weak', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nsubj', 'nermain': '', 'Definite': 'Ind', 'Gender': 'Masc', 'hyper0': 'lac', 'textchildren': 'aflat', 'poschildren': 'VERB', 'lemmachildren': 'afla', 'depchildren': 'acl', 'nerchildren': '', 'Degree': 'Pos'}, 'ENG30-09328904-n'), ({'texthead': 'mergeau', 'poshead': 'VERB', 'lemmahead': 'merge', 'dephead': 'acl', 'nerhead': '', 'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Imp', 'VerbForm': 'Fin', 'text0_0': 'ce', 'pos0_0': 'PRON', 'lemma0_0': 'ce', 'dep0_0': 'nsubj', 'ner0_0': '', 'Case': 'Acc', 'PronType': 'Int,Rel', 'text0_1': 'trestii', 'pos0_1': 'NOUN', 'lemma0_1': 'trestie', 'dep0_1': 'obl', 'ner0_1': '', 'Definite': 'Ind', 'Gender': 'Masc', 'hyper0': 'lac', 'hyper1': 'încăpere', 'hyper2': 'porțiune', 'hyper3': 'construcție', 'hyper4': 'artifact', 'hyper5': 'ansamblu', 'hyper6': 'lucru', 'hyper7': 'ansamblu', 'hyper8': 'lucru', 'text0_2': 'culcare', 'pos0_2': 'NOUN', 'lemma0_2': 'culcare', 'dep0_2': 'obl', 'ner0_2': '', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'obl', 'nermain': '', 'textchildren': 'pe', 'poschildren': 'ADP', 'lemmachildren': 'pe', 'depchildren': 'case', 'nerchildren': '', 'AdpType': 'Prep'}, 'ENG30-09328904-n'), ({'texthead': 'creat', 'poshead': 'VERB', 'lemmahead': 'crea', 'dephead': 'conj', 'nerhead': '', 'Gender': 'Masc', 'Number': 'Sing', 'VerbForm': 'Part', 'text0_0': 's-', 'pos0_0': 'PRON', 'lemma0_0': 'sine', 'dep0_0': 'expl:pass', 'ner0_0': '', 'Case': 'Acc,Nom', 'Person': '3', 'PronType': 'Ind', 'Reflex': 'Yes', 'Strength': 'Weak', 'Variant': 'Short', 'text0_1': 'a', 'pos0_1': 'AUX', 'lemma0_1': 'avea', 'dep0_1': 'aux', 'ner0_1': '', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nsubj:pass', 'nermain': '', 'Definite': 'Ind', 'hyper0': 'țel', 'textchildren': 'scop', 'poschildren': 'NOUN', 'lemmachildren': 'scop', 'depchildren': 'nmod', 'nerchildren': '', 'hyper1': 'finalitate', 'hyper2': 'conținut_cognitiv', 'hyper3': 'înțelegere', 'hyper4': 'trăsătură_psihologică', 'hyper5': 'abstractizare', 'hyper6': 'entitate'}, 'ENG30-09328904-n'), ({'texthead': 'scotea', 'poshead': 'AUX', 'lemmahead': 'scoate', 'dephead': 'ROOT', 'nerhead': '', 'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Imp', 'VerbForm': 'Fin', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'obl', 'nermain': '', 'Definite': 'Def', 'Gender': 'Fem', 'hyper0': 'regiune', 'text0_1': ',', 'pos0_1': 'PUNCT', 'lemma0_1': ',', 'dep0_1': 'punct', 'ner0_1': '', 'text0_2': 'din', 'pos0_2': 'ADP', 'lemma0_2': 'din', 'dep0_2': 'advmod', 'ner0_2': '', 'AdpType': 'Prep', 'Case': 'Acc', 'text0_3': 'broască', 'pos0_3': 'NOUN', 'lemma0_3': 'broască', 'dep0_3': 'nsubj', 'ner0_3': '', 'hyper1': 'ținut', 'hyper2': 'loc', 'hyper3': 'lucru', 'hyper4': 'animal_cu_notocord', 'hyper5': 'animal', 'hyper6': 'organism', 'hyper7': 'creatură', 'hyper8': 'ansamblu', 'text0_4': 'își', 'pos0_4': 'PRON', 'lemma0_4': 'sine', 'dep0_4': 'expl:poss', 'ner0_4': '', 'PronType': 'Prs', 'Reflex': 'Yes', 'Strength': 'Weak', 'text0_5': 'capul', 'pos0_5': 'NOUN', 'lemma0_5': 'cap', 'dep0_5': 'obj', 'ner0_5': '', 'text0_6': 'apei', 'pos0_6': 'NOUN', 'lemma0_6': 'apă', 'dep0_6': 'obl', 'ner0_6': '', 'hyper9': 'lucru', 'text0_7': 'zona', 'pos0_7': 'NOUN', 'lemma0_7': 'zonă', 'dep0_7': 'obl', 'ner0_7': '', 'text0_8': '.', 'pos0_8': 'PUNCT', 'lemma0_8': '.', 'dep0_8': 'punct', 'ner0_8': '', 'textchildren': 'Pe', 'poschildren': 'ADP', 'lemmachildren': 'pe', 'depchildren': 'case', 'nerchildren': ''}, 'ENG30-09328904-n'), ({'texthead': 'insulă', 'poshead': 'NOUN', 'lemmahead': 'insulă', 'dephead': 'obl:pmod', 'nerhead': '', 'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Part', 'text0_0': 'la', 'pos0_0': 'ADP', 'lemma0_0': 'la', 'dep0_0': 'case', 'ner0_0': '', 'Case': 'Dat,Gen', 'Definite': 'Def', 'Gender': 'Fem', 'hyper0': 'lac', 'hyper1': 'zonă', 'hyper2': 'punct_topografic', 'hyper3': 'loc', 'hyper4': 'loc', 'textmain': 'lacului', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nmod', 'nermain': '', 'text0_2': 'încânta', 'pos0_2': 'VERB', 'lemma0_2': 'încânta', 'dep0_2': 'conj', 'ner0_2': '', 'text0_3': 'amplasate', 'pos0_3': 'VERB', 'lemma0_3': 'amplasa', 'dep0_3': 'acl', 'ner0_3': '', 'textchildren': 'a', 'poschildren': 'DET', 'lemmachildren': 'al', 'depchildren': 'det', 'nerchildren': '', 'PronType': 'Prs', 'hyper5': 'lucru', 'hyper6': 'abstractizare', 'hyper7': 'entitate', 'AdpType': 'Prep', 'text0_1': 'o', 'pos0_1': 'DET', 'lemma0_1': 'un', 'dep0_1': 'det', 'ner0_1': '', 'Poss': 'Yes'}, 'ENG30-09328904-n'), ({'texthead': 'maluri', 'poshead': 'NOUN', 'lemmahead': 'mal', 'dephead': 'obl', 'nerhead': '', 'Definite': 'Def', 'Gender': 'Fem', 'Number': 'Plur', 'hyper0': 'lac', 'hyper1': 'formație', 'hyper2': 'lucru', 'text0_0': ',', 'pos0_0': 'PUNCT', 'lemma0_0': ',', 'dep0_0': 'punct', 'ner0_0': '', 'text0_1': 'între', 'pos0_1': 'ADP', 'lemma0_1': 'între', 'dep0_1': 'case', 'ner0_1': '', 'AdpType': 'Prep', 'Case': 'Dat,Gen', 'text0_2': 'două', 'pos0_2': 'NUM', 'lemma0_2': 'doi', 'dep0_2': 'nummod', 'ner0_2': 'NUMERIC_VALUE', 'NumForm': 'Word', 'NumType': 'Card', 'text0_3': 'înalte', 'pos0_3': 'ADJ', 'lemma0_3': 'înalt', 'dep0_3': 'amod', 'ner0_3': '', 'Degree': 'Pos', 'textmain': 'lacului', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nmod', 'nermain': 'LOC', 'textchildren': 'Limanu', 'poschildren': 'PROPN', 'lemmachildren': 'Limanu', 'depchildren': 'nmod', 'nerchildren': 'LOC', 'Poss': 'Yes', 'PronType': 'Prs'}, 'ENG30-09328904-n'), ({}, 'ENG30-09328904-n'), ({'texthead': 'colțișor', 'poshead': 'NOUN', 'lemmahead': 'colțișor', 'dephead': 'nsubj', 'nerhead': '', 'Definite': 'Ind', 'Gender': 'Fem', 'Number': 'Sing', 'text0_0': 'un', 'pos0_0': 'DET', 'lemma0_0': 'un', 'dep0_0': 'det', 'ner0_0': '', 'Case': 'Acc', 'PronType': 'Ind', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nmod', 'nermain': '', 'hyper0': 'claritate', 'text0_2': 'limpezime', 'pos0_2': 'NOUN', 'lemma0_2': 'limpezime', 'dep0_2': 'nmod', 'ner0_2': '', 'hyper1': 'însușire', 'hyper2': 'însușire', 'hyper3': 'abstractizare', 'hyper4': 'entitate', 'textchildren': 'de', 'poschildren': 'ADP', 'lemmachildren': 'de', 'depchildren': 'case', 'nerchildren': '', 'AdpType': 'Prep'}, 'ENG30-09328904-n'), ({'texthead': 'pun', 'poshead': 'AUX', 'lemmahead': 'pune', 'dephead': 'ROOT', 'nerhead': '', 'Mood': 'Ind', 'Number': 'Plur', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin', 'text0_0': 'Umbrele', 'pos0_0': 'NOUN', 'lemma0_0': 'Umbrele', 'dep0_0': 'nsubj', 'ner0_0': '', 'Case': 'Acc', 'Definite': 'Ind', 'Gender': 'Masc', 'text0_1': 'își', 'pos0_1': 'PRON', 'lemma0_1': 'sine', 'dep0_1': 'expl:poss', 'ner0_1': '', 'PronType': 'Prs', 'Reflex': 'Yes', 'Strength': 'Weak', 'text0_2': 'pantofii', 'pos0_2': 'NOUN', 'lemma0_2': 'pantof', 'dep0_2': 'obj', 'ner0_2': 'PRODUCT', 'hyper0': 'lac', 'hyper1': 'încălțăminte', 'hyper2': 'înveliș', 'hyper3': 'artifact', 'hyper4': 'ansamblu', 'hyper5': 'lucru', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'obl', 'nermain': 'PRODUCT', 'text0_4': 'încep', 'pos0_4': 'AUX', 'lemma0_4': 'începe', 'dep0_4': 'conj', 'ner0_4': '', 'text0_5': '.', 'pos0_5': 'PUNCT', 'lemma0_5': '.', 'dep0_5': 'punct', 'ner0_5': '', 'textchildren': 'de', 'poschildren': 'ADP', 'lemmachildren': 'de', 'depchildren': 'case', 'nerchildren': 'PRODUCT', 'AdpType': 'Prep'}, 'ENG30-04159545-n'), ({'texthead': 'pantofi', 'poshead': 'NOUN', 'lemmahead': 'pantof', 'dephead': 'obl', 'nerhead': 'PRODUCT', 'Definite': 'Ind', 'Gender': 'Masc', 'Number': 'Sing', 'hyper0': 'lac', 'hyper1': 'încălțăminte', 'hyper2': 'înveliș', 'hyper3': 'artifact', 'hyper4': 'ansamblu', 'hyper5': 'lucru', 'text0_0': 'În', 'pos0_0': 'ADP', 'lemma0_0': 'în', 'dep0_0': 'case', 'ner0_0': '', 'AdpType': 'Prep', 'Case': 'Acc', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nmod', 'nermain': 'PRODUCT', 'text0_2': ',', 'pos0_2': 'PUNCT', 'lemma0_2': ',', 'dep0_2': 'punct', 'ner0_2': '', 'textchildren': 'de', 'poschildren': 'ADP', 'lemmachildren': 'de', 'depchildren': 'case', 'nerchildren': 'PRODUCT'}, 'ENG30-04159545-n'), ({'texthead': 'pantof', 'poshead': 'NOUN', 'lemmahead': 'pantof', 'dephead': 'nmod', 'nerhead': 'PRODUCT', 'Definite': 'Ind', 'Gender': 'Masc', 'Number': 'Sing', 'hyper0': 'lac', 'hyper1': 'încălțăminte', 'hyper2': 'înveliș', 'hyper3': 'artifact', 'hyper4': 'ansamblu', 'hyper5': 'lucru', 'text0_0': 'cu', 'pos0_0': 'ADP', 'lemma0_0': 'cu', 'dep0_0': 'case', 'ner0_0': '', 'AdpType': 'Prep', 'Case': 'Acc', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nmod', 'nermain': 'PRODUCT', 'textchildren': 'de', 'poschildren': 'ADP', 'lemmachildren': 'de', 'depchildren': 'case', 'nerchildren': 'PRODUCT'}, 'ENG30-04159545-n'), ({'texthead': 'pantofii', 'poshead': 'NOUN', 'lemmahead': 'pantof', 'dephead': 'obj', 'nerhead': 'PRODUCT', 'Case': 'Acc', 'Definite': 'Def', 'Gender': 'Masc', 'Number': 'Sing', 'hyper0': 'bunel', 'hyper1': 'bunic', 'hyper2': 'străbun', 'hyper3': 'ascendent', 'hyper4': 'neam', 'hyper5': 'individ', 'text0_0': 'negri', 'pos0_0': 'ADJ', 'lemma0_0': 'negru', 'dep0_0': 'amod', 'ner0_0': 'PRODUCT', 'Degree': 'Pos', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nmod', 'nermain': 'PRODUCT', 'text0_2': 'bunicului', 'pos0_2': 'NOUN', 'lemma0_2': 'bunic', 'dep0_2': 'nmod', 'ner0_2': 'PERSON', 'hyper6': 'organism', 'hyper7': 'creatură', 'hyper8': 'ansamblu', 'hyper9': 'lucru', 'textchildren': 'de', 'poschildren': 'ADP', 'lemmachildren': 'de', 'depchildren': 'case', 'nerchildren': 'PRODUCT', 'AdpType': 'Prep'}, 'ENG30-04159545-n'), ({'texthead': 'lei', 'poshead': 'NOUN', 'lemmahead': 'leu', 'dephead': 'nmod', 'nerhead': 'MONEY', 'Definite': 'Ind', 'Gender': 'Fem', 'Number': 'Plur', 'hyper0': 'unghie', 'hyper1': 'ungvis', 'hyper2': 'structură_anatomică', 'hyper3': 'parte_a_corpului', 'hyper4': 'bucată', 'hyper5': 'lucru', 'hyper6': 'vertebrat', 'hyper7': 'animal_cu_notocord', 'hyper8': 'animal', 'hyper9': 'organism', 'hyper10': 'creatură', 'hyper11': 'ansamblu', 'hyper12': 'lucru', 'text0_0': '303', 'pos0_0': '', 'lemma0_0': '303', 'dep0_0': 'nummod', 'ner0_0': 'MONEY', 'text0_1': 'de', 'pos0_1': 'ADP', 'lemma0_1': 'de', 'dep0_1': 'case', 'ner0_1': 'MONEY', 'AdpType': 'Prep', 'Case': 'Acc', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'conj', 'nermain': '', 'text0_3': 'lei', 'pos0_3': 'NOUN', 'lemma0_3': 'leu', 'dep0_3': 'conj', 'ner0_3': 'MONEY', 'text0_4': 'lei', 'pos0_4': 'NOUN', 'lemma0_4': 'leu', 'dep0_4': 'appos', 'ner0_4': 'MONEY', 'textchildren': 'unghii', 'poschildren': 'NOUN', 'lemmachildren': 'unghie', 'depchildren': 'nmod', 'nerchildren': ''}, 'ENG30-14991004-n'), ({'texthead': 'produce', 'poshead': 'AUX', 'lemmahead': 'produce', 'dephead': 'ROOT', 'nerhead': '', 'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin', 'text0_0': 'Designerul', 'pos0_0': 'NOUN', 'lemma0_0': 'designer', 'dep0_0': 'nsubj', 'ner0_0': 'PERSON', 'Case': 'Acc,Nom', 'Definite': 'Ind', 'Gender': 'Fem', 'hyper0': 'unghie', 'hyper1': 'ungvis', 'hyper2': 'structură_anatomică', 'hyper3': 'parte_a_corpului', 'hyper4': 'bucată', 'hyper5': 'lucru', 'hyper6': 'ansamblu', 'hyper7': 'lucru', 'text0_1': 'Azature', 'pos0_1': 'PROPN', 'lemma0_1': 'Azature', 'dep0_1': 'nsubj', 'ner0_1': 'PRODUCT', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'obj', 'nermain': '', 'text0_3': '.', 'pos0_3': 'PUNCT', 'lemma0_3': '.', 'dep0_3': 'punct', 'ner0_3': '', 'textchildren': 'are', 'poschildren': 'AUX', 'lemmachildren': 'avea', 'depchildren': 'acl', 'nerchildren': '', 'PronType': 'Ind'}, 'ENG30-14991004-n'), ({'texthead': 'ruj', 'poshead': 'NOUN', 'lemmahead': 'ruj', 'dephead': 'appos', 'nerhead': '', 'Definite': 'Ind', 'Gender': 'Fem', 'Number': 'Plur', 'hyper0': 'unghie', 'hyper1': 'ungvis', 'hyper2': 'structură_anatomică', 'hyper3': 'parte_a_corpului', 'hyper4': 'bucată', 'hyper5': 'lucru', 'hyper6': 'ansamblu', 'hyper7': 'lucru', 'text0_0': ':', 'pos0_0': 'PUNCT', 'lemma0_0': ':', 'dep0_0': 'punct', 'ner0_0': '', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'conj', 'nermain': '', 'text0_2': 'pudriere', 'pos0_2': 'ADJ', 'lemma0_2': 'pudrier', 'dep0_2': 'conj', 'ner0_2': '', 'Degree': 'Pos', 'text0_3': ',', 'pos0_3': 'PUNCT', 'lemma0_3': ',', 'dep0_3': 'punct', 'ner0_3': '', 'textchildren': 'unghii', 'poschildren': 'NOUN', 'lemmachildren': 'unghie', 'depchildren': 'nmod', 'nerchildren': ''}, 'ENG30-14991004-n'), ({'texthead': 'lac', 'poshead': 'NOUN', 'lemmahead': 'lac', 'dephead': 'conj', 'nerhead': '', 'text0_0': ',', 'pos0_0': 'PUNCT', 'lemma0_0': ',', 'dep0_0': 'punct', 'ner0_0': '', 'text0_1': 'unghii', 'pos0_1': 'NOUN', 'lemma0_1': 'unghie', 'dep0_1': 'nmod', 'ner0_1': '', 'Definite': 'Ind', 'Gender': 'Fem', 'Number': 'Plur', 'hyper0': 'tampon', 'hyper1': 'obturator', 'hyper2': 'dop', 'hyper3': 'obstacol', 'hyper4': 'construcție', 'text0_2': 'Aut', 'pos0_2': 'PROPN', 'lemma0_2': 'Aut', 'dep0_2': 'nmod', 'ner0_2': 'ORGANIZATION', 'text0_3': 'luciu', 'pos0_3': 'ADJ', 'lemma0_3': 'luciu', 'dep0_3': 'amod', 'ner0_3': '', 'Degree': 'Pos', 'text0_4': 'fard', 'pos0_4': 'NOUN', 'lemma0_4': 'fard', 'dep0_4': 'conj', 'ner0_4': '', 'hyper5': 'artifact', 'hyper6': 'ansamblu', 'text0_5': '...', 'pos0_5': 'PUNCT', 'lemma0_5': '...', 'dep0_5': 'punct', 'ner0_5': 'EVENT', 'textmain': 'Lacul', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nmod', 'nermain': 'LOC', 'text0_7': '...', 'pos0_7': 'PUNCT', 'lemma0_7': '...', 'dep0_7': 'punct', 'ner0_7': '', 'text0_8': 'pudră', 'pos0_8': 'NOUN', 'lemma0_8': 'pudră', 'dep0_8': 'nmod', 'ner0_8': '', 'Case': 'Acc,Nom', 'text0_9': '...', 'pos0_9': 'PUNCT', 'lemma0_9': '...', 'dep0_9': 'punct', 'ner0_9': 'ORGANIZATION', 'text0_10': 'ruj', 'pos0_10': 'NOUN', 'lemma0_10': 'ruj', 'dep0_10': 'nmod', 'ner0_10': 'ORGANIZATION', 'hyper7': 'lucru', 'text0_11': '...', 'pos0_11': 'PUNCT', 'lemma0_11': '...', 'dep0_11': 'punct', 'ner0_11': '', 'text0_12': 'spray', 'pos0_12': 'NOUN', 'lemma0_12': 'spray', 'dep0_12': 'nmod', 'ner0_12': 'PRODUCT', 'text0_13': 'șampon', 'pos0_13': 'NOUN', 'lemma0_13': 'șampon', 'dep0_13': 'conj', 'ner0_13': '', 'text0_14': 'lac', 'pos0_14': 'NOUN', 'lemma0_14': 'lac', 'dep0_14': 'conj', 'ner0_14': '', 'textchildren': 'tampoane', 'poschildren': 'NOUN', 'lemmachildren': 'tampon', 'depchildren': 'conj', 'nerchildren': 'PRODUCT', 'Mood': 'Ind', 'Person': '2', 'Tense': 'Imp', 'VerbForm': 'Fin', 'text0_6': 'lac', 'pos0_6': 'NOUN', 'lemma0_6': 'lac', 'dep0_6': 'nmod', 'ner0_6': 'EVENT'}, 'ENG30-14991004-n'), ({'texthead': 'rămășițe', 'poshead': 'NOUN', 'lemmahead': 'rămășiță', 'dephead': 'conj', 'nerhead': '', 'Definite': 'Ind', 'Gender': 'Fem', 'Number': 'Plur', 'hyper0': 'unghie', 'hyper1': 'ungvis', 'text0_0': ',', 'pos0_0': 'PUNCT', 'lemma0_0': ',', 'dep0_0': 'punct', 'ner0_0': '', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nmod', 'nermain': '', 'textchildren': 'unghii', 'poschildren': 'NOUN', 'lemmachildren': 'unghie', 'depchildren': 'nmod', 'nerchildren': '', 'AdpType': 'Prep', 'Case': 'Acc', 'hyper2': 'structură_anatomică', 'hyper3': 'parte_a_corpului', 'hyper4': 'bucată', 'hyper5': 'lucru'}, 'ENG30-14991004-n'), ({'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'ROOT', 'nermain': '', 'Definite': 'Def', 'Gender': 'Fem', 'Number': 'Sing', 'hyper0': 'vârf_de_gamă', 'textchildren': 'gama', 'poschildren': 'NOUN', 'lemmachildren': 'gamă', 'depchildren': 'appos', 'nerchildren': '', 'hyper1': 'marfă', 'hyper2': 'bun', 'hyper3': 'artifact', 'hyper4': 'ansamblu', 'hyper5': 'lucru', 'hyper6': 'vertebrat', 'hyper7': 'animal_cu_notocord', 'hyper8': 'animal', 'hyper9': 'organism', 'hyper10': 'creatură', 'hyper11': 'ansamblu', 'hyper12': 'lucru', 'Case': 'Acc,Nom'}, 'ENG30-14991004-n'), ({'texthead': 'flacoanele', 'poshead': 'NOUN', 'lemmahead': 'flacoan', 'dephead': 'nmod', 'nerhead': '', 'Case': 'Acc', 'Definite': 'Ind', 'Gender': 'Fem', 'Number': 'Plur', 'text0_0': 'din', 'pos0_0': 'ADP', 'lemma0_0': 'din', 'dep0_0': 'case', 'ner0_0': '', 'AdpType': 'Prep', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nmod', 'nermain': '', 'hyper0': 'unghie', 'textchildren': 'unghii', 'poschildren': 'NOUN', 'lemmachildren': 'unghie', 'depchildren': 'nmod', 'nerchildren': '', 'hyper1': 'ungvis', 'hyper2': 'structură_anatomică', 'hyper3': 'parte_a_corpului', 'hyper4': 'bucată', 'hyper5': 'lucru'}, 'ENG30-14991004-n'), ({'texthead': 'flacoanele', 'poshead': 'NOUN', 'lemmahead': 'flacoan', 'dephead': 'nmod', 'nerhead': '', 'Case': 'Acc', 'Definite': 'Ind', 'Gender': 'Fem', 'Number': 'Plur', 'text0_0': 'din', 'pos0_0': 'ADP', 'lemma0_0': 'din', 'dep0_0': 'case', 'ner0_0': '', 'AdpType': 'Prep', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nmod', 'nermain': '', 'hyper0': 'unghie', 'textchildren': 'unghii', 'poschildren': 'NOUN', 'lemmachildren': 'unghie', 'depchildren': 'nmod', 'nerchildren': '', 'hyper1': 'ungvis', 'hyper2': 'structură_anatomică', 'hyper3': 'parte_a_corpului', 'hyper4': 'bucată', 'hyper5': 'lucru'}, 'ENG30-14991004-n'), ({'texthead': 'Dizolvant', 'poshead': 'ADJ', 'lemmahead': 'Dizolvant', 'dephead': 'appos', 'nerhead': 'WORK_OF_ART', 'Definite': 'Ind', 'Degree': 'Pos', 'Gender': 'Fem', 'Number': 'Plur', 'text0_0': '-', 'pos0_0': 'PUNCT', 'lemma0_0': '-', 'dep0_0': 'punct', 'ner0_0': 'WORK_OF_ART', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'obl', 'nermain': 'WORK_OF_ART', 'hyper0': 'unghie', 'text0_2': '246', 'pos0_2': '', 'lemma0_2': '246', 'dep0_2': 'nummod', 'ner0_2': 'NUMERIC_VALUE', 'textchildren': 'unghii', 'poschildren': 'NOUN', 'lemmachildren': 'unghie', 'depchildren': 'nmod', 'nerchildren': 'WORK_OF_ART', 'AdpType': 'Prep', 'Case': 'Acc', 'hyper1': 'ungvis', 'hyper2': 'structură_anatomică', 'hyper3': 'parte_a_corpului', 'hyper4': 'bucată', 'hyper5': 'lucru'}, 'ENG30-14991004-n'), ({'texthead': 'machiaj', 'poshead': 'NOUN', 'lemmahead': 'machiaj', 'dephead': 'obl', 'nerhead': 'PRODUCT', 'Definite': 'Ind', 'Gender': 'Fem', 'Number': 'Plur', 'text0_0': 'pentru', 'pos0_0': 'ADP', 'lemma0_0': 'pentru', 'dep0_0': 'case', 'ner0_0': 'PRODUCT', 'AdpType': 'Prep', 'Case': 'Acc', 'text0_1': 'Gerovital', 'pos0_1': 'NOUN', 'lemma0_1': 'Gerovital', 'dep0_1': 'nmod', 'ner0_1': 'PRODUCT', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'conj', 'nermain': '', 'hyper0': 'unghie', 'textchildren': 'unghii', 'poschildren': 'NOUN', 'lemmachildren': 'unghie', 'depchildren': 'nmod', 'nerchildren': '', 'Polarity': 'Pos', 'hyper1': 'ungvis', 'hyper2': 'structură_anatomică', 'hyper3': 'parte_a_corpului', 'hyper4': 'bucată', 'hyper5': 'lucru'}, 'ENG30-14991004-n'), ({'texthead': 'producem', 'poshead': 'VERB', 'lemmahead': 'produce', 'dephead': 'ccomp', 'nerhead': '', 'Mood': 'Ind', 'Number': 'Plur', 'Person': '1', 'Tense': 'Pres', 'VerbForm': 'Fin', 'text0_0': 'Acum', 'pos0_0': 'ADV', 'lemma0_0': 'acum', 'dep0_0': 'advmod', 'ner0_0': '', 'Degree': 'Pos', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'obj', 'nermain': '', 'Definite': 'Ind', 'Gender': 'Fem', 'hyper0': 'unghie', 'textchildren': 'unghii', 'poschildren': 'NOUN', 'lemmachildren': 'unghie', 'depchildren': 'nmod', 'nerchildren': '', 'AdpType': 'Prep', 'Case': 'Acc', 'hyper1': 'ungvis', 'hyper2': 'structură_anatomică', 'hyper3': 'parte_a_corpului', 'hyper4': 'bucată', 'hyper5': 'lucru'}, 'ENG30-14991004-n'), ({'texthead': 'zărește', 'poshead': 'AUX', 'lemmahead': 'zări', 'dephead': 'ROOT', 'nerhead': '', 'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Past', 'VerbForm': 'Fin', 'text0_0': 'departe', 'pos0_0': 'ADV', 'lemma0_0': 'departe', 'dep0_0': 'advmod', 'ner0_0': '', 'Degree': 'Pos', 'text0_1': 'se', 'pos0_1': 'PRON', 'lemma0_1': 'sine', 'dep0_1': 'expl:pass', 'ner0_1': '', 'Case': 'Acc,Nom', 'PronType': 'Prs', 'Reflex': 'Yes', 'Strength': 'Weak', 'textmain': 'Lacul', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nsubj', 'nermain': '', 'Definite': 'Def', 'Gender': 'Masc', 'hyper0': 'lac', 'text0_3': 'trestii', 'pos0_3': 'NOUN', 'lemma0_3': 'trestie', 'dep0_3': 'obl', 'ner0_3': '', 'hyper1': 'graminee', 'hyper2': 'erbacee', 'hyper3': 'vascular', 'hyper4': 'plantă', 'hyper5': 'organism', 'hyper6': 'creatură', 'hyper7': 'ansamblu', 'hyper8': 'lucru', 'text0_4': 'tresărind', 'pos0_4': 'AUX', 'lemma0_4': 'tresări', 'dep0_4': 'advcl', 'ner0_4': '', 'text0_5': 'albe/', 'pos0_5': 'X', 'lemma0_5': 'albe/', 'dep0_5': 'nsubj:pass', 'ner0_5': '', 'text0_6': 'cutremură', 'pos0_6': 'VERB', 'lemma0_6': 'cutremura', 'dep0_6': 'parataxis', 'ner0_6': '', 'text0_7': 'Lacul', 'pos0_7': 'NOUN', 'lemma0_7': 'lac', 'dep0_7': 'nsubj', 'ner0_7': '', 'text0_8': '.', 'pos0_8': 'PUNCT', 'lemma0_8': '.', 'dep0_8': 'punct', 'ner0_8': '', 'textchildren': ')', 'poschildren': 'PUNCT', 'lemmachildren': ')', 'depchildren': 'punct', 'nerchildren': '', 'text0_2': 'lac', 'pos0_2': 'NOUN', 'lemma0_2': 'lac', 'dep0_2': 'nsubj:pass', 'ner0_2': ''}, 'ENG30-09351547-n'), ({'texthead': 'lăsat', 'poshead': 'VERB', 'lemmahead': 'lăsa', 'dephead': 'ROOT', 'nerhead': '', 'Gender': 'Masc', 'Number': 'Plur', 'VerbForm': 'Part', 'text0_0': 'Ne-', 'pos0_0': 'PRON', 'lemma0_0': 'Ne-', 'dep0_0': 'iobj', 'ner0_0': '', 'Case': 'Dat,Gen', 'Person': '3', 'PronType': 'Prs', 'Strength': 'Weak', 'Variant': 'Short', 'text0_1': 'a', 'pos0_1': 'AUX', 'lemma0_1': 'avea', 'dep0_1': 'aux', 'ner0_1': '', 'text0_2': 'dorința', 'pos0_2': 'NOUN', 'lemma0_2': 'dorință', 'dep0_2': 'obj', 'ner0_2': '', 'Definite': 'Def', 'hyper0': 'poveste', 'hyper1': 'ficțiune', 'hyper2': 'compoziție', 'hyper3': 'scriere', 'hyper4': 'comunicare_scrisă', 'hyper5': 'comunicare', 'textmain': 'lacul', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'obl', 'nermain': 'LOC', 'text0_4': 'poveste', 'pos0_4': 'NOUN', 'lemma0_4': 'poveste', 'dep0_4': 'conj', 'ner0_4': '', 'hyper6': 'abstractizare', 'hyper7': 'entitate', 'text0_5': '.', 'pos0_5': 'PUNCT', 'lemma0_5': '.', 'dep0_5': 'punct', 'ner0_5': '', 'textchildren': '”', 'poschildren': 'PUNCT', 'lemmachildren': '”', 'depchildren': 'punct', 'nerchildren': '', 'AdpType': 'Prep'}, 'ENG30-09351547-n'), ({'textmain': 'lacul', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'ROOT', 'nermain': 'LOC', 'Case': 'Acc,Nom', 'Definite': 'Def', 'Gender': 'Fem', 'Number': 'Plur', 'hyper0': 'liliac', 'textchildren': '.', 'poschildren': 'PUNCT', 'lemmachildren': '.', 'depchildren': 'punct', 'nerchildren': '', 'hyper1': 'tufă', 'hyper2': 'plantă_lemnoasă', 'hyper3': 'vascular', 'hyper4': 'plantă', 'hyper5': 'organism', 'hyper6': 'creatură', 'hyper7': 'ansamblu', 'hyper8': 'lucru'}, 'ENG30-09351547-n'), ({'texthead': 'ochi', 'poshead': 'NOUN', 'lemmahead': 'ochi', 'dephead': 'nmod', 'nerhead': 'PRODUCT', 'Definite': 'Ind', 'Gender': 'Masc', 'hyper0': 'lac', 'hyper1': 'receptor', 'hyper2': 'organ', 'hyper3': 'parte_a_corpului', 'hyper4': 'bucată', 'hyper5': 'lucru', 'text0_0': 'cu', 'pos0_0': 'ADP', 'lemma0_0': 'cu', 'dep0_0': 'case', 'ner0_0': 'PRODUCT', 'AdpType': 'Prep', 'Case': 'Acc', 'textmain': 'lac', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nmod', 'nermain': '', 'Number': 'Sing', 'textchildren': 'adânc', 'poschildren': 'ADJ', 'lemmachildren': 'adânc', 'depchildren': 'amod', 'nerchildren': '', 'Degree': 'Pos'}, 'ENG30-09351547-n'), ({'texthead': 'secat', 'poshead': 'VERB', 'lemmahead': 'seca', 'dephead': 'ccomp', 'nerhead': '', 'Gender': 'Masc', 'Number': 'Plur', 'VerbForm': 'Part', 'text0_0': 'că', 'pos0_0': 'SCONJ', 'lemma0_0': 'că', 'dep0_0': 'mark', 'ner0_0': '', 'Polarity': 'Pos', 'textmain': 'lacul', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nsubj', 'nermain': 'FACILITY', 'Case': 'Dat,Gen', 'Definite': 'Def', 'hyper0': 'lac', 'text0_2': 'a', 'pos0_2': 'AUX', 'lemma0_2': 'avea', 'dep0_2': 'aux', 'ner0_2': '', 'Person': '3', 'text0_3': 'EMINESCU', 'pos0_3': 'PROPN', 'lemma0_3': 'EMINESCU', 'dep0_3': 'obj', 'ner0_3': '', 'textchildren': 'codrilor', 'poschildren': 'NOUN', 'lemmachildren': 'codr', 'depchildren': 'nmod', 'nerchildren': 'FACILITY'}, 'ENG30-09351547-n'), ({'texthead': 'spus', 'poshead': 'VERB', 'lemmahead': 'spune', 'dephead': 'parataxis', 'nerhead': '', 'Definite': 'Def', 'Gender': 'Masc', 'Number': 'Plur', 'hyper0': 'lac', 'hyper1': 'iepure', 'hyper2': 'leporide', 'hyper3': 'lagomorf', 'hyper4': 'placentar', 'text0_0': '(', 'pos0_0': 'PUNCT', 'lemma0_0': '(', 'dep0_0': 'punct', 'ner0_0': '', 'Case': 'Dat,Gen', 'PronType': 'Prs', 'text0_1': 'căruia', 'pos0_1': 'PRON', 'lemma0_1': 'care', 'dep0_1': 'iobj', 'ner0_1': '', 'hyper5': 'mamifer', 'hyper6': 'vertebrat', 'textmain': 'lacul', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'obj', 'nermain': 'LOC', 'textchildren': '\"', 'poschildren': 'PUNCT', 'lemmachildren': '\"', 'depchildren': 'punct', 'nerchildren': 'LOC', 'Polarity': 'Pos', 'hyper7': 'animal_cu_notocord', 'hyper8': 'animal', 'hyper9': 'organism', 'hyper10': 'creatură', 'hyper11': 'ansamblu', 'hyper12': 'lucru', 'VerbForm': 'Part', 'Person': '3', 'text0_2': 'i', 'pos0_2': 'PRON', 'lemma0_2': 'el', 'dep0_2': 'expl', 'ner0_2': '', 'Strength': 'Weak', 'text0_3': 's-', 'pos0_3': 'PRON', 'lemma0_3': 'sine', 'dep0_3': 'expl:pv', 'ner0_3': '', 'Reflex': 'Yes', 'Variant': 'Short', 'text0_4': 'a', 'pos0_4': 'AUX', 'lemma0_4': 'avea', 'dep0_4': 'aux', 'ner0_4': '', 'text0_6': ')', 'pos0_6': 'PUNCT', 'lemma0_6': ')', 'dep0_6': 'punct', 'ner0_6': '', 'text0_7': 'nuferi', 'pos0_7': 'NOUN', 'lemma0_7': 'nufer', 'dep0_7': 'obl', 'ner0_7': ''}, 'ENG30-09351547-n'), ({'texthead': 'arată', 'poshead': 'VERB', 'lemmahead': 'arăta', 'dephead': 'ROOT', 'nerhead': '', 'Mood': 'Ind', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin', 'text0_0': 'aburul', 'pos0_0': 'NOUN', 'lemma0_0': 'abur', 'dep0_0': 'obl', 'ner0_0': 'PRODUCT', 'Case': 'Dat,Gen', 'Definite': 'Def', 'Gender': 'Masc', 'Number': 'Plur', 'hyper0': 'lac', 'hyper1': 'navă', 'hyper2': 'navă', 'hyper3': 'vehicul', 'hyper4': 'mijloc_de_circulație', 'hyper5': 'mijloc_de_transport', 'hyper6': 'instrument', 'hyper7': 'artifact', 'hyper8': 'ansamblu', 'hyper9': 'lucru', 'text0_1': 'totul', 'pos0_1': 'PRON', 'lemma0_1': 'tot', 'dep0_1': 'nsubj', 'ner0_1': '', 'PronType': 'Ind', 'text0_2': 'nobil', 'pos0_2': 'ADJ', 'lemma0_2': 'nobil', 'dep0_2': 'xcomp', 'ner0_2': '', 'Degree': 'Pos', 'text0_3': 'caută', 'pos0_3': 'VERB', 'lemma0_3': 'căuta', 'dep0_3': 'conj', 'ner0_3': '', 'textmain': 'lacul', 'posmain': 'NOUN', 'lemmamain': 'lac', 'depmain': 'nsubj', 'nermain': 'LOC', 'text0_5': 'limpezesc', 'pos0_5': 'AUX', 'lemma0_5': 'limpezi', 'dep0_5': 'conj', 'ner0_5': '', 'text0_6': 'copilăresc', 'pos0_6': 'ADJ', 'lemma0_6': 'copilăresc', 'dep0_6': 'conj', 'ner0_6': '', 'text0_7': 'înțelepțesc', 'pos0_7': 'AUX', 'lemma0_7': 'înțelepți', 'dep0_7': 'conj', 'ner0_7': 'LOC', 'text0_8': '.', 'pos0_8': 'PUNCT', 'lemma0_8': '.', 'dep0_8': 'punct', 'ner0_8': '', 'textchildren': '”', 'poschildren': 'PUNCT', 'lemmachildren': '”', 'depchildren': 'punct', 'nerchildren': 'LOC', 'Polarity': 'Pos', 'AdpType': 'Prep'}, 'ENG30-09351547-n')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crearea si antrenarea a cate un model de clasificare pentru fiecare cuvant target din datele de intrare**"
      ],
      "metadata": {
        "id": "6lbeweEtMNnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "algorithm = nltk.classify.MaxentClassifier.ALGORITHMS[0]\n",
        "classifiers = {}\n",
        "\n",
        "for w in a.keys():\n",
        "  print(w)\n",
        "  classifier = nltk.MaxentClassifier.train(a[w], algorithm, max_iter=50)\n",
        "  classifiers[w] = classifier\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkNN-3uCYEPM",
        "outputId": "9ed1ca62-932e-4370-8b70-72f7eeb54acf"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lac\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.323\n",
            "             2          -1.16265        0.790\n",
            "             3          -0.99692        0.839\n",
            "             4          -0.87220        0.887\n",
            "             5          -0.77552        0.903\n",
            "             6          -0.69840        0.903\n",
            "             7          -0.63539        0.919\n",
            "             8          -0.58286        0.935\n",
            "             9          -0.53836        0.952\n",
            "            10          -0.50014        0.952\n",
            "            11          -0.46695        0.968\n",
            "            12          -0.43783        0.968\n",
            "            13          -0.41209        0.968\n",
            "            14          -0.38915        0.968\n",
            "            15          -0.36859        0.984\n",
            "            16          -0.35006        0.984\n",
            "            17          -0.33326        1.000\n",
            "            18          -0.31796        1.000\n",
            "            19          -0.30397        1.000\n",
            "            20          -0.29113        1.000\n",
            "            21          -0.27931        1.000\n",
            "            22          -0.26838        1.000\n",
            "            23          -0.25825        1.000\n",
            "            24          -0.24884        1.000\n",
            "            25          -0.24007        1.000\n",
            "            26          -0.23188        1.000\n",
            "            27          -0.22421        1.000\n",
            "            28          -0.21702        1.000\n",
            "            29          -0.21026        1.000\n",
            "            30          -0.20390        1.000\n",
            "            31          -0.19790        1.000\n",
            "            32          -0.19223        1.000\n",
            "            33          -0.18687        1.000\n",
            "            34          -0.18179        1.000\n",
            "            35          -0.17697        1.000\n",
            "            36          -0.17239        1.000\n",
            "            37          -0.16804        1.000\n",
            "            38          -0.16389        1.000\n",
            "            39          -0.15994        1.000\n",
            "            40          -0.15617        1.000\n",
            "            41          -0.15256        1.000\n",
            "            42          -0.14912        1.000\n",
            "            43          -0.14582        1.000\n",
            "            44          -0.14266        1.000\n",
            "            45          -0.13963        1.000\n",
            "            46          -0.13672        1.000\n",
            "            47          -0.13393        1.000\n",
            "            48          -0.13124        1.000\n",
            "            49          -0.12866        1.000\n",
            "         Final          -0.12618        1.000\n",
            "lin\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.250\n",
            "             2          -0.98207        1.000\n",
            "             3          -0.73779        1.000\n",
            "             4          -0.58239        1.000\n",
            "             5          -0.47733        1.000\n",
            "             6          -0.40251        1.000\n",
            "             7          -0.34695        1.000\n",
            "             8          -0.30427        1.000\n",
            "             9          -0.27056        1.000\n",
            "            10          -0.24333        1.000\n",
            "            11          -0.22092        1.000\n",
            "            12          -0.20216        1.000\n",
            "            13          -0.18626        1.000\n",
            "            14          -0.17261        1.000\n",
            "            15          -0.16078        1.000\n",
            "            16          -0.15043        1.000\n",
            "            17          -0.14131        1.000\n",
            "            18          -0.13320        1.000\n",
            "            19          -0.12596        1.000\n",
            "            20          -0.11944        1.000\n",
            "            21          -0.11356        1.000\n",
            "            22          -0.10822        1.000\n",
            "            23          -0.10335        1.000\n",
            "            24          -0.09889        1.000\n",
            "            25          -0.09480        1.000\n",
            "            26          -0.09103        1.000\n",
            "            27          -0.08754        1.000\n",
            "            28          -0.08430        1.000\n",
            "            29          -0.08129        1.000\n",
            "            30          -0.07849        1.000\n",
            "            31          -0.07587        1.000\n",
            "            32          -0.07342        1.000\n",
            "            33          -0.07112        1.000\n",
            "            34          -0.06896        1.000\n",
            "            35          -0.06692        1.000\n",
            "            36          -0.06500        1.000\n",
            "            37          -0.06319        1.000\n",
            "            38          -0.06147        1.000\n",
            "            39          -0.05985        1.000\n",
            "            40          -0.05831        1.000\n",
            "            41          -0.05684        1.000\n",
            "            42          -0.05544        1.000\n",
            "            43          -0.05412        1.000\n",
            "            44          -0.05285        1.000\n",
            "            45          -0.05164        1.000\n",
            "            46          -0.05048        1.000\n",
            "            47          -0.04938        1.000\n",
            "            48          -0.04832        1.000\n",
            "            49          -0.04731        1.000\n",
            "         Final          -0.04633        1.000\n",
            "mare\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.79176        0.585\n",
            "             2          -1.19015        0.908\n",
            "             3          -0.88397        0.923\n",
            "             4          -0.70897        0.954\n",
            "             5          -0.59488        0.954\n",
            "             6          -0.51361        0.985\n",
            "             7          -0.45220        0.985\n",
            "             8          -0.40385        1.000\n",
            "             9          -0.36463        1.000\n",
            "            10          -0.33212        1.000\n",
            "            11          -0.30470        1.000\n",
            "            12          -0.28126        1.000\n",
            "            13          -0.26101        1.000\n",
            "            14          -0.24334        1.000\n",
            "            15          -0.22780        1.000\n",
            "            16          -0.21403        1.000\n",
            "            17          -0.20176        1.000\n",
            "            18          -0.19075        1.000\n",
            "            19          -0.18083        1.000\n",
            "            20          -0.17185        1.000\n",
            "            21          -0.16368        1.000\n",
            "            22          -0.15623        1.000\n",
            "            23          -0.14939        1.000\n",
            "            24          -0.14311        1.000\n",
            "            25          -0.13731        1.000\n",
            "            26          -0.13195        1.000\n",
            "            27          -0.12698        1.000\n",
            "            28          -0.12235        1.000\n",
            "            29          -0.11804        1.000\n",
            "            30          -0.11402        1.000\n",
            "            31          -0.11025        1.000\n",
            "            32          -0.10671        1.000\n",
            "            33          -0.10339        1.000\n",
            "            34          -0.10027        1.000\n",
            "            35          -0.09732        1.000\n",
            "            36          -0.09453        1.000\n",
            "            37          -0.09190        1.000\n",
            "            38          -0.08940        1.000\n",
            "            39          -0.08704        1.000\n",
            "            40          -0.08479        1.000\n",
            "            41          -0.08265        1.000\n",
            "            42          -0.08062        1.000\n",
            "            43          -0.07868        1.000\n",
            "            44          -0.07683        1.000\n",
            "            45          -0.07506        1.000\n",
            "            46          -0.07337        1.000\n",
            "            47          -0.07176        1.000\n",
            "            48          -0.07021        1.000\n",
            "            49          -0.06873        1.000\n",
            "         Final          -0.06730        1.000\n",
            "masa\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.94591        0.111\n",
            "             2          -1.94591        0.111\n",
            "             3          -1.94591        0.111\n",
            "             4          -1.94591        0.111\n",
            "             5          -1.94591        0.111\n",
            "             6          -1.94591        0.111\n",
            "             7          -1.94591        0.111\n",
            "             8          -1.94591        0.111\n",
            "             9          -1.94591        0.111\n",
            "            10          -1.94591        0.111\n",
            "            11          -1.94591        0.111\n",
            "            12          -1.94591        0.111\n",
            "            13          -1.94591        0.111\n",
            "            14          -1.94591        0.111\n",
            "            15          -1.94591        0.111\n",
            "            16          -1.94591        0.111\n",
            "            17          -1.94591        0.111\n",
            "            18          -1.94591        0.111\n",
            "            19          -1.94591        0.111\n",
            "            20          -1.94591        0.111\n",
            "            21          -1.94591        0.111\n",
            "            22          -1.94591        0.111\n",
            "            23          -1.94591        0.111\n",
            "            24          -1.94591        0.111\n",
            "            25          -1.94591        0.111\n",
            "            26          -1.94591        0.111\n",
            "            27          -1.94591        0.111\n",
            "            28          -1.94591        0.111\n",
            "            29          -1.94591        0.111\n",
            "            30          -1.94591        0.111\n",
            "            31          -1.94591        0.111\n",
            "            32          -1.94591        0.111\n",
            "            33          -1.94591        0.111\n",
            "            34          -1.94591        0.111\n",
            "            35          -1.94591        0.111\n",
            "            36          -1.94591        0.111\n",
            "            37          -1.94591        0.111\n",
            "            38          -1.94591        0.111\n",
            "            39          -1.94591        0.111\n",
            "            40          -1.94591        0.111\n",
            "            41          -1.94591        0.111\n",
            "            42          -1.94591        0.111\n",
            "            43          -1.94591        0.111\n",
            "            44          -1.94591        0.111\n",
            "            45          -1.94591        0.111\n",
            "            46          -1.94591        0.111\n",
            "            47          -1.94591        0.111\n",
            "            48          -1.94591        0.111\n",
            "            49          -1.94591        0.111\n",
            "         Final          -1.94591        0.111\n",
            "opus\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.300\n",
            "             2          -1.22349        0.650\n",
            "             3          -1.10699        0.650\n",
            "             4          -1.02146        0.650\n",
            "             5          -0.95618        0.650\n",
            "             6          -0.90473        0.650\n",
            "             7          -0.86314        0.650\n",
            "             8          -0.82879        0.650\n",
            "             9          -0.79994        0.650\n",
            "            10          -0.77534        0.650\n",
            "            11          -0.75411        0.650\n",
            "            12          -0.73560        0.650\n",
            "            13          -0.71930        0.650\n",
            "            14          -0.70485        0.650\n",
            "            15          -0.69195        0.650\n",
            "            16          -0.68035        0.650\n",
            "            17          -0.66987        0.650\n",
            "            18          -0.66036        0.650\n",
            "            19          -0.65169        0.650\n",
            "            20          -0.64375        0.650\n",
            "            21          -0.63646        0.650\n",
            "            22          -0.62974        0.650\n",
            "            23          -0.62352        0.650\n",
            "            24          -0.61776        0.650\n",
            "            25          -0.61240        0.650\n",
            "            26          -0.60740        0.650\n",
            "            27          -0.60274        0.650\n",
            "            28          -0.59837        0.650\n",
            "            29          -0.59427        0.650\n",
            "            30          -0.59042        0.650\n",
            "            31          -0.58680        0.650\n",
            "            32          -0.58338        0.650\n",
            "            33          -0.58015        0.650\n",
            "            34          -0.57710        0.650\n",
            "            35          -0.57420        0.650\n",
            "            36          -0.57146        0.650\n",
            "            37          -0.56885        0.650\n",
            "            38          -0.56637        0.650\n",
            "            39          -0.56401        0.650\n",
            "            40          -0.56176        0.650\n",
            "            41          -0.55961        0.650\n",
            "            42          -0.55756        0.650\n",
            "            43          -0.55560        0.650\n",
            "            44          -0.55372        0.650\n",
            "            45          -0.55192        0.650\n",
            "            46          -0.55020        0.650\n",
            "            47          -0.54855        0.650\n",
            "            48          -0.54696        0.650\n",
            "            49          -0.54543        0.650\n",
            "         Final          -0.54396        0.650\n",
            "pană\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.143\n",
            "             2          -0.97198        1.000\n",
            "             3          -0.74219        1.000\n",
            "             4          -0.59916        1.000\n",
            "             5          -0.50102        1.000\n",
            "             6          -0.42937        1.000\n",
            "             7          -0.37480        1.000\n",
            "             8          -0.33193        1.000\n",
            "             9          -0.29744        1.000\n",
            "            10          -0.26913        1.000\n",
            "            11          -0.24552        1.000\n",
            "            12          -0.22555        1.000\n",
            "            13          -0.20846        1.000\n",
            "            14          -0.19369        1.000\n",
            "            15          -0.18079        1.000\n",
            "            16          -0.16945        1.000\n",
            "            17          -0.15940        1.000\n",
            "            18          -0.15044        1.000\n",
            "            19          -0.14240        1.000\n",
            "            20          -0.13515        1.000\n",
            "            21          -0.12858        1.000\n",
            "            22          -0.12261        1.000\n",
            "            23          -0.11715        1.000\n",
            "            24          -0.11215        1.000\n",
            "            25          -0.10754        1.000\n",
            "            26          -0.10329        1.000\n",
            "            27          -0.09936        1.000\n",
            "            28          -0.09570        1.000\n",
            "            29          -0.09231        1.000\n",
            "            30          -0.08914        1.000\n",
            "            31          -0.08617        1.000\n",
            "            32          -0.08339        1.000\n",
            "            33          -0.08079        1.000\n",
            "            34          -0.07834        1.000\n",
            "            35          -0.07603        1.000\n",
            "            36          -0.07385        1.000\n",
            "            37          -0.07179        1.000\n",
            "            38          -0.06984        1.000\n",
            "            39          -0.06799        1.000\n",
            "            40          -0.06623        1.000\n",
            "            41          -0.06457        1.000\n",
            "            42          -0.06298        1.000\n",
            "            43          -0.06147        1.000\n",
            "            44          -0.06002        1.000\n",
            "            45          -0.05865        1.000\n",
            "            46          -0.05733        1.000\n",
            "            47          -0.05607        1.000\n",
            "            48          -0.05487        1.000\n",
            "            49          -0.05371        1.000\n",
            "         Final          -0.05261        1.000\n",
            "păr\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.259\n",
            "             2          -0.93398        0.852\n",
            "             3          -0.81417        0.852\n",
            "             4          -0.72362        0.852\n",
            "             5          -0.65294        0.889\n",
            "             6          -0.59623        0.889\n",
            "             7          -0.54963        0.926\n",
            "             8          -0.51054        0.926\n",
            "             9          -0.47718        0.926\n",
            "            10          -0.44826        0.926\n",
            "            11          -0.42289        0.926\n",
            "            12          -0.40037        0.926\n",
            "            13          -0.38020        0.926\n",
            "            14          -0.36201        0.926\n",
            "            15          -0.34548        0.926\n",
            "            16          -0.33038        0.963\n",
            "            17          -0.31652        0.963\n",
            "            18          -0.30374        0.963\n",
            "            19          -0.29192        1.000\n",
            "            20          -0.28094        1.000\n",
            "            21          -0.27073        1.000\n",
            "            22          -0.26119        1.000\n",
            "            23          -0.25228        1.000\n",
            "            24          -0.24392        1.000\n",
            "            25          -0.23607        1.000\n",
            "            26          -0.22868        1.000\n",
            "            27          -0.22172        1.000\n",
            "            28          -0.21515        1.000\n",
            "            29          -0.20893        1.000\n",
            "            30          -0.20305        1.000\n",
            "            31          -0.19748        1.000\n",
            "            32          -0.19219        1.000\n",
            "            33          -0.18716        1.000\n",
            "            34          -0.18238        1.000\n",
            "            35          -0.17782        1.000\n",
            "            36          -0.17348        1.000\n",
            "            37          -0.16933        1.000\n",
            "            38          -0.16537        1.000\n",
            "            39          -0.16159        1.000\n",
            "            40          -0.15797        1.000\n",
            "            41          -0.15450        1.000\n",
            "            42          -0.15117        1.000\n",
            "            43          -0.14798        1.000\n",
            "            44          -0.14491        1.000\n",
            "            45          -0.14197        1.000\n",
            "            46          -0.13914        1.000\n",
            "            47          -0.13641        1.000\n",
            "            48          -0.13379        1.000\n",
            "            49          -0.13126        1.000\n",
            "         Final          -0.12883        1.000\n",
            "para\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.60944        0.071\n",
            "             2          -1.27361        0.857\n",
            "             3          -1.05311        0.893\n",
            "             4          -0.90168        0.893\n",
            "             5          -0.79127        0.893\n",
            "             6          -0.70705        0.893\n",
            "             7          -0.64063        0.893\n",
            "             8          -0.58690        0.893\n",
            "             9          -0.54257        0.893\n",
            "            10          -0.50539        0.893\n",
            "            11          -0.47379        0.893\n",
            "            12          -0.44662        0.893\n",
            "            13          -0.42303        0.893\n",
            "            14          -0.40235        0.893\n",
            "            15          -0.38410        0.893\n",
            "            16          -0.36788        0.893\n",
            "            17          -0.35336        0.893\n",
            "            18          -0.34030        0.893\n",
            "            19          -0.32850        0.893\n",
            "            20          -0.31777        0.893\n",
            "            21          -0.30798        0.893\n",
            "            22          -0.29902        0.893\n",
            "            23          -0.29078        0.893\n",
            "            24          -0.28317        0.893\n",
            "            25          -0.27613        0.893\n",
            "            26          -0.26960        0.893\n",
            "            27          -0.26352        0.893\n",
            "            28          -0.25785        0.893\n",
            "            29          -0.25255        0.893\n",
            "            30          -0.24757        0.893\n",
            "            31          -0.24290        0.893\n",
            "            32          -0.23851        0.893\n",
            "            33          -0.23436        0.893\n",
            "            34          -0.23044        0.893\n",
            "            35          -0.22674        0.893\n",
            "            36          -0.22323        0.893\n",
            "            37          -0.21989        0.893\n",
            "            38          -0.21673        0.893\n",
            "            39          -0.21371        0.893\n",
            "            40          -0.21084        0.893\n",
            "            41          -0.20810        0.893\n",
            "            42          -0.20549        0.893\n",
            "            43          -0.20299        0.893\n",
            "            44          -0.20059        0.893\n",
            "            45          -0.19830        0.893\n",
            "            46          -0.19610        0.893\n",
            "            47          -0.19399        0.893\n",
            "            48          -0.19196        0.893\n",
            "            49          -0.19001        0.893\n",
            "         Final          -0.18814        0.893\n",
            "nouă\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -2.07944        0.103\n",
            "             2          -1.97219        0.103\n",
            "             3          -1.93583        0.103\n",
            "             4          -1.91764        0.103\n",
            "             5          -1.90674        0.103\n",
            "             6          -1.89947        0.103\n",
            "             7          -1.89429        0.103\n",
            "             8          -1.89040        0.103\n",
            "             9          -1.88737        0.103\n",
            "            10          -1.88495        0.103\n",
            "            11          -1.88298        0.103\n",
            "            12          -1.88133        0.103\n",
            "            13          -1.87993        0.103\n",
            "            14          -1.87874        0.103\n",
            "            15          -1.87770        0.103\n",
            "            16          -1.87680        0.103\n",
            "            17          -1.87600        0.103\n",
            "            18          -1.87529        0.103\n",
            "            19          -1.87465        0.103\n",
            "            20          -1.87408        0.103\n",
            "            21          -1.87356        0.103\n",
            "            22          -1.87309        0.103\n",
            "            23          -1.87266        0.103\n",
            "            24          -1.87227        0.103\n",
            "            25          -1.87190        0.103\n",
            "            26          -1.87157        0.103\n",
            "            27          -1.87126        0.103\n",
            "            28          -1.87097        0.103\n",
            "            29          -1.87071        0.103\n",
            "            30          -1.87046        0.103\n",
            "            31          -1.87022        0.103\n",
            "            32          -1.87000        0.103\n",
            "            33          -1.86980        0.103\n",
            "            34          -1.86960        0.103\n",
            "            35          -1.86942        0.103\n",
            "            36          -1.86925        0.103\n",
            "            37          -1.86909        0.103\n",
            "            38          -1.86893        0.103\n",
            "            39          -1.86878        0.103\n",
            "            40          -1.86865        0.103\n",
            "            41          -1.86851        0.103\n",
            "            42          -1.86839        0.103\n",
            "            43          -1.86827        0.103\n",
            "            44          -1.86815        0.103\n",
            "            45          -1.86804        0.103\n",
            "            46          -1.86794        0.103\n",
            "            47          -1.86784        0.103\n",
            "            48          -1.86774        0.103\n",
            "            49          -1.86765        0.103\n",
            "         Final          -1.86756        0.103\n",
            "bancă\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.125\n",
            "             2          -0.82193        0.875\n",
            "             3          -0.58105        1.000\n",
            "             4          -0.44984        1.000\n",
            "             5          -0.36613        1.000\n",
            "             6          -0.30776        1.000\n",
            "             7          -0.26473        1.000\n",
            "             8          -0.23175        1.000\n",
            "             9          -0.20575        1.000\n",
            "            10          -0.18476        1.000\n",
            "            11          -0.16749        1.000\n",
            "            12          -0.15306        1.000\n",
            "            13          -0.14084        1.000\n",
            "            14          -0.13036        1.000\n",
            "            15          -0.12130        1.000\n",
            "            16          -0.11337        1.000\n",
            "            17          -0.10640        1.000\n",
            "            18          -0.10021        1.000\n",
            "            19          -0.09468        1.000\n",
            "            20          -0.08973        1.000\n",
            "            21          -0.08525        1.000\n",
            "            22          -0.08119        1.000\n",
            "            23          -0.07750        1.000\n",
            "            24          -0.07412        1.000\n",
            "            25          -0.07102        1.000\n",
            "            26          -0.06816        1.000\n",
            "            27          -0.06552        1.000\n",
            "            28          -0.06308        1.000\n",
            "            29          -0.06081        1.000\n",
            "            30          -0.05869        1.000\n",
            "            31          -0.05672        1.000\n",
            "            32          -0.05487        1.000\n",
            "            33          -0.05314        1.000\n",
            "            34          -0.05152        1.000\n",
            "            35          -0.04998        1.000\n",
            "            36          -0.04854        1.000\n",
            "            37          -0.04718        1.000\n",
            "            38          -0.04589        1.000\n",
            "            39          -0.04467        1.000\n",
            "            40          -0.04351        1.000\n",
            "            41          -0.04241        1.000\n",
            "            42          -0.04136        1.000\n",
            "            43          -0.04037        1.000\n",
            "            44          -0.03942        1.000\n",
            "            45          -0.03851        1.000\n",
            "            46          -0.03765        1.000\n",
            "            47          -0.03682        1.000\n",
            "            48          -0.03603        1.000\n",
            "            49          -0.03527        1.000\n",
            "         Final          -0.03454        1.000\n",
            "broască\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.364\n",
            "             2          -0.49996        1.000\n",
            "             3          -0.39355        1.000\n",
            "             4          -0.32546        1.000\n",
            "             5          -0.27768        1.000\n",
            "             6          -0.24214        1.000\n",
            "             7          -0.21462        1.000\n",
            "             8          -0.19265        1.000\n",
            "             9          -0.17472        1.000\n",
            "            10          -0.15980        1.000\n",
            "            11          -0.14720        1.000\n",
            "            12          -0.13642        1.000\n",
            "            13          -0.12709        1.000\n",
            "            14          -0.11894        1.000\n",
            "            15          -0.11177        1.000\n",
            "            16          -0.10539        1.000\n",
            "            17          -0.09970        1.000\n",
            "            18          -0.09459        1.000\n",
            "            19          -0.08997        1.000\n",
            "            20          -0.08577        1.000\n",
            "            21          -0.08195        1.000\n",
            "            22          -0.07845        1.000\n",
            "            23          -0.07523        1.000\n",
            "            24          -0.07227        1.000\n",
            "            25          -0.06953        1.000\n",
            "            26          -0.06698        1.000\n",
            "            27          -0.06462        1.000\n",
            "            28          -0.06241        1.000\n",
            "            29          -0.06035        1.000\n",
            "            30          -0.05842        1.000\n",
            "            31          -0.05661        1.000\n",
            "            32          -0.05491        1.000\n",
            "            33          -0.05330        1.000\n",
            "            34          -0.05179        1.000\n",
            "            35          -0.05036        1.000\n",
            "            36          -0.04900        1.000\n",
            "            37          -0.04772        1.000\n",
            "            38          -0.04650        1.000\n",
            "            39          -0.04534        1.000\n",
            "            40          -0.04424        1.000\n",
            "            41          -0.04319        1.000\n",
            "            42          -0.04219        1.000\n",
            "            43          -0.04123        1.000\n",
            "            44          -0.04032        1.000\n",
            "            45          -0.03944        1.000\n",
            "            46          -0.03861        1.000\n",
            "            47          -0.03780        1.000\n",
            "            48          -0.03703        1.000\n",
            "            49          -0.03629        1.000\n",
            "         Final          -0.03558        1.000\n",
            "călca\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.200\n",
            "             2          -0.72874        1.000\n",
            "             3          -0.54499        1.000\n",
            "             4          -0.43684        1.000\n",
            "             5          -0.36499        1.000\n",
            "             6          -0.31343        1.000\n",
            "             7          -0.27449        1.000\n",
            "             8          -0.24400        1.000\n",
            "             9          -0.21948        1.000\n",
            "            10          -0.19933        1.000\n",
            "            11          -0.18250        1.000\n",
            "            12          -0.16824        1.000\n",
            "            13          -0.15600        1.000\n",
            "            14          -0.14539        1.000\n",
            "            15          -0.13611        1.000\n",
            "            16          -0.12792        1.000\n",
            "            17          -0.12065        1.000\n",
            "            18          -0.11414        1.000\n",
            "            19          -0.10830        1.000\n",
            "            20          -0.10301        1.000\n",
            "            21          -0.09821        1.000\n",
            "            22          -0.09383        1.000\n",
            "            23          -0.08983        1.000\n",
            "            24          -0.08614        1.000\n",
            "            25          -0.08274        1.000\n",
            "            26          -0.07960        1.000\n",
            "            27          -0.07669        1.000\n",
            "            28          -0.07398        1.000\n",
            "            29          -0.07145        1.000\n",
            "            30          -0.06908        1.000\n",
            "            31          -0.06687        1.000\n",
            "            32          -0.06479        1.000\n",
            "            33          -0.06284        1.000\n",
            "            34          -0.06100        1.000\n",
            "            35          -0.05927        1.000\n",
            "            36          -0.05763        1.000\n",
            "            37          -0.05607        1.000\n",
            "            38          -0.05460        1.000\n",
            "            39          -0.05320        1.000\n",
            "            40          -0.05187        1.000\n",
            "            41          -0.05061        1.000\n",
            "            42          -0.04940        1.000\n",
            "            43          -0.04825        1.000\n",
            "            44          -0.04716        1.000\n",
            "            45          -0.04611        1.000\n",
            "            46          -0.04510        1.000\n",
            "            47          -0.04414        1.000\n",
            "            48          -0.04322        1.000\n",
            "            49          -0.04234        1.000\n",
            "         Final          -0.04149        1.000\n",
            "car\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.500\n",
            "             2          -0.49355        1.000\n",
            "             3          -0.37816        1.000\n",
            "             4          -0.30421        1.000\n",
            "             5          -0.25325        1.000\n",
            "             6          -0.21625        1.000\n",
            "             7          -0.18828        1.000\n",
            "             8          -0.16646        1.000\n",
            "             9          -0.14901        1.000\n",
            "            10          -0.13476        1.000\n",
            "            11          -0.12291        1.000\n",
            "            12          -0.11293        1.000\n",
            "            13          -0.10440        1.000\n",
            "            14          -0.09703        1.000\n",
            "            15          -0.09062        1.000\n",
            "            16          -0.08498        1.000\n",
            "            17          -0.07998        1.000\n",
            "            18          -0.07553        1.000\n",
            "            19          -0.07154        1.000\n",
            "            20          -0.06794        1.000\n",
            "            21          -0.06467        1.000\n",
            "            22          -0.06170        1.000\n",
            "            23          -0.05899        1.000\n",
            "            24          -0.05650        1.000\n",
            "            25          -0.05421        1.000\n",
            "            26          -0.05210        1.000\n",
            "            27          -0.05014        1.000\n",
            "            28          -0.04832        1.000\n",
            "            29          -0.04663        1.000\n",
            "            30          -0.04505        1.000\n",
            "            31          -0.04357        1.000\n",
            "            32          -0.04218        1.000\n",
            "            33          -0.04088        1.000\n",
            "            34          -0.03966        1.000\n",
            "            35          -0.03850        1.000\n",
            "            36          -0.03742        1.000\n",
            "            37          -0.03639        1.000\n",
            "            38          -0.03541        1.000\n",
            "            39          -0.03448        1.000\n",
            "            40          -0.03361        1.000\n",
            "            41          -0.03277        1.000\n",
            "            42          -0.03197        1.000\n",
            "            43          -0.03122        1.000\n",
            "            44          -0.03049        1.000\n",
            "            45          -0.02980        1.000\n",
            "            46          -0.02914        1.000\n",
            "            47          -0.02851        1.000\n",
            "            48          -0.02790        1.000\n",
            "            49          -0.02732        1.000\n",
            "         Final          -0.02677        1.000\n",
            "colonie\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.667\n",
            "             2          -0.77354        0.833\n",
            "             3          -0.60449        0.917\n",
            "             4          -0.50144        0.917\n",
            "             5          -0.43121        0.917\n",
            "             6          -0.37977        0.917\n",
            "             7          -0.34018        0.917\n",
            "             8          -0.30862        0.917\n",
            "             9          -0.28277        0.917\n",
            "            10          -0.26115        1.000\n",
            "            11          -0.24276        1.000\n",
            "            12          -0.22689        1.000\n",
            "            13          -0.21305        1.000\n",
            "            14          -0.20084        1.000\n",
            "            15          -0.19000        1.000\n",
            "            16          -0.18029        1.000\n",
            "            17          -0.17154        1.000\n",
            "            18          -0.16361        1.000\n",
            "            19          -0.15639        1.000\n",
            "            20          -0.14979        1.000\n",
            "            21          -0.14372        1.000\n",
            "            22          -0.13813        1.000\n",
            "            23          -0.13296        1.000\n",
            "            24          -0.12816        1.000\n",
            "            25          -0.12369        1.000\n",
            "            26          -0.11953        1.000\n",
            "            27          -0.11563        1.000\n",
            "            28          -0.11199        1.000\n",
            "            29          -0.10856        1.000\n",
            "            30          -0.10534        1.000\n",
            "            31          -0.10230        1.000\n",
            "            32          -0.09943        1.000\n",
            "            33          -0.09671        1.000\n",
            "            34          -0.09414        1.000\n",
            "            35          -0.09170        1.000\n",
            "            36          -0.08939        1.000\n",
            "            37          -0.08718        1.000\n",
            "            38          -0.08509        1.000\n",
            "            39          -0.08309        1.000\n",
            "            40          -0.08118        1.000\n",
            "            41          -0.07935        1.000\n",
            "            42          -0.07761        1.000\n",
            "            43          -0.07594        1.000\n",
            "            44          -0.07434        1.000\n",
            "            45          -0.07280        1.000\n",
            "            46          -0.07133        1.000\n",
            "            47          -0.06992        1.000\n",
            "            48          -0.06856        1.000\n",
            "            49          -0.06725        1.000\n",
            "         Final          -0.06599        1.000\n",
            "consola\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.125\n",
            "             2          -0.64967        0.875\n",
            "             3          -0.48845        0.938\n",
            "             4          -0.40670        0.938\n",
            "             5          -0.35659        0.938\n",
            "             6          -0.32241        0.938\n",
            "             7          -0.29746        0.938\n",
            "             8          -0.27839        0.938\n",
            "             9          -0.26330        0.938\n",
            "            10          -0.25105        0.938\n",
            "            11          -0.24090        0.938\n",
            "            12          -0.23235        0.938\n",
            "            13          -0.22505        0.938\n",
            "            14          -0.21875        0.938\n",
            "            15          -0.21324        0.938\n",
            "            16          -0.20840        0.938\n",
            "            17          -0.20410        0.938\n",
            "            18          -0.20027        0.938\n",
            "            19          -0.19682        0.938\n",
            "            20          -0.19371        0.938\n",
            "            21          -0.19089        0.938\n",
            "            22          -0.18832        0.938\n",
            "            23          -0.18596        0.938\n",
            "            24          -0.18380        0.938\n",
            "            25          -0.18181        0.938\n",
            "            26          -0.17997        0.938\n",
            "            27          -0.17826        0.938\n",
            "            28          -0.17667        0.938\n",
            "            29          -0.17519        0.938\n",
            "            30          -0.17381        0.938\n",
            "            31          -0.17252        0.938\n",
            "            32          -0.17130        0.938\n",
            "            33          -0.17016        0.938\n",
            "            34          -0.16909        0.938\n",
            "            35          -0.16807        0.938\n",
            "            36          -0.16711        0.938\n",
            "            37          -0.16621        0.938\n",
            "            38          -0.16535        0.938\n",
            "            39          -0.16453        0.938\n",
            "            40          -0.16376        0.938\n",
            "            41          -0.16302        0.938\n",
            "            42          -0.16232        0.938\n",
            "            43          -0.16165        0.938\n",
            "            44          -0.16101        0.938\n",
            "            45          -0.16040        0.938\n",
            "            46          -0.15981        0.938\n",
            "            47          -0.15925        0.938\n",
            "            48          -0.15871        0.938\n",
            "            49          -0.15820        0.938\n",
            "         Final          -0.15770        0.938\n",
            "casa\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.190\n",
            "             2          -1.38629        0.190\n",
            "             3          -1.38629        0.190\n",
            "             4          -1.38629        0.190\n",
            "             5          -1.38629        0.190\n",
            "             6          -1.38629        0.190\n",
            "             7          -1.38629        0.190\n",
            "             8          -1.38629        0.190\n",
            "             9          -1.38629        0.190\n",
            "            10          -1.38629        0.190\n",
            "            11          -1.38629        0.190\n",
            "            12          -1.38629        0.190\n",
            "            13          -1.38629        0.190\n",
            "            14          -1.38629        0.190\n",
            "            15          -1.38629        0.190\n",
            "            16          -1.38629        0.190\n",
            "            17          -1.38629        0.190\n",
            "            18          -1.38629        0.190\n",
            "            19          -1.38629        0.190\n",
            "            20          -1.38629        0.190\n",
            "            21          -1.38629        0.190\n",
            "            22          -1.38629        0.190\n",
            "            23          -1.38629        0.190\n",
            "            24          -1.38629        0.190\n",
            "            25          -1.38629        0.190\n",
            "            26          -1.38629        0.190\n",
            "            27          -1.38629        0.190\n",
            "            28          -1.38629        0.190\n",
            "            29          -1.38629        0.190\n",
            "            30          -1.38629        0.190\n",
            "            31          -1.38629        0.190\n",
            "            32          -1.38629        0.190\n",
            "            33          -1.38629        0.190\n",
            "            34          -1.38629        0.190\n",
            "            35          -1.38629        0.190\n",
            "            36          -1.38629        0.190\n",
            "            37          -1.38629        0.190\n",
            "            38          -1.38629        0.190\n",
            "            39          -1.38629        0.190\n",
            "            40          -1.38629        0.190\n",
            "            41          -1.38629        0.190\n",
            "            42          -1.38629        0.190\n",
            "            43          -1.38629        0.190\n",
            "            44          -1.38629        0.190\n",
            "            45          -1.38629        0.190\n",
            "            46          -1.38629        0.190\n",
            "            47          -1.38629        0.190\n",
            "            48          -1.38629        0.190\n",
            "            49          -1.38629        0.190\n",
            "         Final          -1.38629        0.190\n",
            "accident\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.333\n",
            "             2          -0.82303        0.800\n",
            "             3          -0.67354        0.867\n",
            "             4          -0.57580        0.933\n",
            "             5          -0.50415        1.000\n",
            "             6          -0.44843        1.000\n",
            "             7          -0.40362        1.000\n",
            "             8          -0.36676        1.000\n",
            "             9          -0.33591        1.000\n",
            "            10          -0.30972        1.000\n",
            "            11          -0.28723        1.000\n",
            "            12          -0.26772        1.000\n",
            "            13          -0.25063        1.000\n",
            "            14          -0.23555        1.000\n",
            "            15          -0.22214        1.000\n",
            "            16          -0.21015        1.000\n",
            "            17          -0.19935        1.000\n",
            "            18          -0.18960        1.000\n",
            "            19          -0.18073        1.000\n",
            "            20          -0.17264        1.000\n",
            "            21          -0.16523        1.000\n",
            "            22          -0.15841        1.000\n",
            "            23          -0.15213        1.000\n",
            "            24          -0.14632        1.000\n",
            "            25          -0.14092        1.000\n",
            "            26          -0.13590        1.000\n",
            "            27          -0.13122        1.000\n",
            "            28          -0.12685        1.000\n",
            "            29          -0.12275        1.000\n",
            "            30          -0.11891        1.000\n",
            "            31          -0.11529        1.000\n",
            "            32          -0.11188        1.000\n",
            "            33          -0.10867        1.000\n",
            "            34          -0.10563        1.000\n",
            "            35          -0.10276        1.000\n",
            "            36          -0.10003        1.000\n",
            "            37          -0.09744        1.000\n",
            "            38          -0.09498        1.000\n",
            "            39          -0.09264        1.000\n",
            "            40          -0.09042        1.000\n",
            "            41          -0.08829        1.000\n",
            "            42          -0.08626        1.000\n",
            "            43          -0.08432        1.000\n",
            "            44          -0.08246        1.000\n",
            "            45          -0.08069        1.000\n",
            "            46          -0.07898        1.000\n",
            "            47          -0.07735        1.000\n",
            "            48          -0.07578        1.000\n",
            "            49          -0.07427        1.000\n",
            "         Final          -0.07282        1.000\n",
            "acru\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.154\n",
            "             2          -0.83419        1.000\n",
            "             3          -0.67372        1.000\n",
            "             4          -0.56697        1.000\n",
            "             5          -0.49030        1.000\n",
            "             6          -0.43216        1.000\n",
            "             7          -0.38636        1.000\n",
            "             8          -0.34925        1.000\n",
            "             9          -0.31852        1.000\n",
            "            10          -0.29266        1.000\n",
            "            11          -0.27058        1.000\n",
            "            12          -0.25151        1.000\n",
            "            13          -0.23488        1.000\n",
            "            14          -0.22026        1.000\n",
            "            15          -0.20730        1.000\n",
            "            16          -0.19574        1.000\n",
            "            17          -0.18536        1.000\n",
            "            18          -0.17600        1.000\n",
            "            19          -0.16752        1.000\n",
            "            20          -0.15979        1.000\n",
            "            21          -0.15273        1.000\n",
            "            22          -0.14625        1.000\n",
            "            23          -0.14028        1.000\n",
            "            24          -0.13477        1.000\n",
            "            25          -0.12967        1.000\n",
            "            26          -0.12493        1.000\n",
            "            27          -0.12052        1.000\n",
            "            28          -0.11640        1.000\n",
            "            29          -0.11254        1.000\n",
            "            30          -0.10893        1.000\n",
            "            31          -0.10554        1.000\n",
            "            32          -0.10235        1.000\n",
            "            33          -0.09934        1.000\n",
            "            34          -0.09650        1.000\n",
            "            35          -0.09382        1.000\n",
            "            36          -0.09128        1.000\n",
            "            37          -0.08887        1.000\n",
            "            38          -0.08658        1.000\n",
            "            39          -0.08440        1.000\n",
            "            40          -0.08233        1.000\n",
            "            41          -0.08036        1.000\n",
            "            42          -0.07848        1.000\n",
            "            43          -0.07668        1.000\n",
            "            44          -0.07496        1.000\n",
            "            45          -0.07332        1.000\n",
            "            46          -0.07174        1.000\n",
            "            47          -0.07024        1.000\n",
            "            48          -0.06879        1.000\n",
            "            49          -0.06740        1.000\n",
            "         Final          -0.06606        1.000\n",
            "alpaca\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.778\n",
            "             2          -0.50168        0.889\n",
            "             3          -0.39349        1.000\n",
            "             4          -0.32448        1.000\n",
            "             5          -0.27646        1.000\n",
            "             6          -0.24097        1.000\n",
            "             7          -0.21361        1.000\n",
            "             8          -0.19183        1.000\n",
            "             9          -0.17406        1.000\n",
            "            10          -0.15928        1.000\n",
            "            11          -0.14679        1.000\n",
            "            12          -0.13609        1.000\n",
            "            13          -0.12683        1.000\n",
            "            14          -0.11873        1.000\n",
            "            15          -0.11159        1.000\n",
            "            16          -0.10525        1.000\n",
            "            17          -0.09957        1.000\n",
            "            18          -0.09447        1.000\n",
            "            19          -0.08986        1.000\n",
            "            20          -0.08567        1.000\n",
            "            21          -0.08185        1.000\n",
            "            22          -0.07835        1.000\n",
            "            23          -0.07514        1.000\n",
            "            24          -0.07217        1.000\n",
            "            25          -0.06942        1.000\n",
            "            26          -0.06688        1.000\n",
            "            27          -0.06451        1.000\n",
            "            28          -0.06230        1.000\n",
            "            29          -0.06024        1.000\n",
            "            30          -0.05830        1.000\n",
            "            31          -0.05649        1.000\n",
            "            32          -0.05478        1.000\n",
            "            33          -0.05317        1.000\n",
            "            34          -0.05166        1.000\n",
            "            35          -0.05022        1.000\n",
            "            36          -0.04887        1.000\n",
            "            37          -0.04758        1.000\n",
            "            38          -0.04636        1.000\n",
            "            39          -0.04520        1.000\n",
            "            40          -0.04409        1.000\n",
            "            41          -0.04304        1.000\n",
            "            42          -0.04204        1.000\n",
            "            43          -0.04108        1.000\n",
            "            44          -0.04016        1.000\n",
            "            45          -0.03928        1.000\n",
            "            46          -0.03844        1.000\n",
            "            47          -0.03764        1.000\n",
            "            48          -0.03687        1.000\n",
            "            49          -0.03613        1.000\n",
            "         Final          -0.03541        1.000\n",
            "abate\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.250\n",
            "             2          -0.50586        0.875\n",
            "             3          -0.41469        0.875\n",
            "             4          -0.36126        0.875\n",
            "             5          -0.32592        0.875\n",
            "             6          -0.30062        0.875\n",
            "             7          -0.28147        0.875\n",
            "             8          -0.26640        0.875\n",
            "             9          -0.25417        0.875\n",
            "            10          -0.24404        0.875\n",
            "            11          -0.23548        0.875\n",
            "            12          -0.22814        0.875\n",
            "            13          -0.22179        0.875\n",
            "            14          -0.21623        0.875\n",
            "            15          -0.21132        0.875\n",
            "            16          -0.20695        0.875\n",
            "            17          -0.20304        0.875\n",
            "            18          -0.19952        0.875\n",
            "            19          -0.19634        0.875\n",
            "            20          -0.19344        0.875\n",
            "            21          -0.19080        0.875\n",
            "            22          -0.18838        0.875\n",
            "            23          -0.18615        0.875\n",
            "            24          -0.18409        0.875\n",
            "            25          -0.18218        0.875\n",
            "            26          -0.18041        0.875\n",
            "            27          -0.17877        0.875\n",
            "            28          -0.17723        0.875\n",
            "            29          -0.17579        0.875\n",
            "            30          -0.17445        0.875\n",
            "            31          -0.17318        0.875\n",
            "            32          -0.17199        0.875\n",
            "            33          -0.17087        0.875\n",
            "            34          -0.16981        0.875\n",
            "            35          -0.16881        0.875\n",
            "            36          -0.16787        0.875\n",
            "            37          -0.16697        0.875\n",
            "            38          -0.16611        0.875\n",
            "            39          -0.16530        0.875\n",
            "            40          -0.16453        0.875\n",
            "            41          -0.16379        0.875\n",
            "            42          -0.16309        0.875\n",
            "            43          -0.16242        0.875\n",
            "            44          -0.16178        0.875\n",
            "            45          -0.16116        0.875\n",
            "            46          -0.16057        0.875\n",
            "            47          -0.16001        0.875\n",
            "            48          -0.15947        0.875\n",
            "            49          -0.15895        0.875\n",
            "         Final          -0.15845        0.875\n",
            "anticar\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.556\n",
            "             2          -0.53653        1.000\n",
            "             3          -0.44052        1.000\n",
            "             4          -0.37522        1.000\n",
            "             5          -0.32760        1.000\n",
            "             6          -0.29119        1.000\n",
            "             7          -0.26235        1.000\n",
            "             8          -0.23890        1.000\n",
            "             9          -0.21941        1.000\n",
            "            10          -0.20294        1.000\n",
            "            11          -0.18883        1.000\n",
            "            12          -0.17659        1.000\n",
            "            13          -0.16587        1.000\n",
            "            14          -0.15640        1.000\n",
            "            15          -0.14796        1.000\n",
            "            16          -0.14039        1.000\n",
            "            17          -0.13357        1.000\n",
            "            18          -0.12738        1.000\n",
            "            19          -0.12174        1.000\n",
            "            20          -0.11658        1.000\n",
            "            21          -0.11184        1.000\n",
            "            22          -0.10748        1.000\n",
            "            23          -0.10344        1.000\n",
            "            24          -0.09969        1.000\n",
            "            25          -0.09620        1.000\n",
            "            26          -0.09295        1.000\n",
            "            27          -0.08991        1.000\n",
            "            28          -0.08706        1.000\n",
            "            29          -0.08439        1.000\n",
            "            30          -0.08187        1.000\n",
            "            31          -0.07950        1.000\n",
            "            32          -0.07726        1.000\n",
            "            33          -0.07515        1.000\n",
            "            34          -0.07314        1.000\n",
            "            35          -0.07124        1.000\n",
            "            36          -0.06943        1.000\n",
            "            37          -0.06772        1.000\n",
            "            38          -0.06608        1.000\n",
            "            39          -0.06452        1.000\n",
            "            40          -0.06303        1.000\n",
            "            41          -0.06161        1.000\n",
            "            42          -0.06025        1.000\n",
            "            43          -0.05895        1.000\n",
            "            44          -0.05770        1.000\n",
            "            45          -0.05651        1.000\n",
            "            46          -0.05536        1.000\n",
            "            47          -0.05426        1.000\n",
            "            48          -0.05320        1.000\n",
            "            49          -0.05218        1.000\n",
            "         Final          -0.05120        1.000\n",
            "vin\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.429\n",
            "             2          -0.56507        0.429\n",
            "             3          -0.50493        0.429\n",
            "             4          -0.46996        0.429\n",
            "             5          -0.44704        0.429\n",
            "             6          -0.43084        0.429\n",
            "             7          -0.41878        0.429\n",
            "             8          -0.40945        0.429\n",
            "             9          -0.40202        0.429\n",
            "            10          -0.39595        0.429\n",
            "            11          -0.39091        0.429\n",
            "            12          -0.38666        0.429\n",
            "            13          -0.38302        0.429\n",
            "            14          -0.37987        0.429\n",
            "            15          -0.37712        0.429\n",
            "            16          -0.37470        0.429\n",
            "            17          -0.37255        0.429\n",
            "            18          -0.37062        0.429\n",
            "            19          -0.36889        0.429\n",
            "            20          -0.36733        0.429\n",
            "            21          -0.36591        0.429\n",
            "            22          -0.36462        0.429\n",
            "            23          -0.36343        0.429\n",
            "            24          -0.36234        0.429\n",
            "            25          -0.36133        0.429\n",
            "            26          -0.36040        0.429\n",
            "            27          -0.35954        0.429\n",
            "            28          -0.35874        0.429\n",
            "            29          -0.35799        0.429\n",
            "            30          -0.35728        0.429\n",
            "            31          -0.35663        0.429\n",
            "            32          -0.35601        0.429\n",
            "            33          -0.35543        0.429\n",
            "            34          -0.35488        0.429\n",
            "            35          -0.35437        0.429\n",
            "            36          -0.35388        0.429\n",
            "            37          -0.35342        0.429\n",
            "            38          -0.35298        0.429\n",
            "            39          -0.35256        0.429\n",
            "            40          -0.35217        0.429\n",
            "            41          -0.35179        0.429\n",
            "            42          -0.35143        0.429\n",
            "            43          -0.35109        0.429\n",
            "            44          -0.35076        0.429\n",
            "            45          -0.35045        0.429\n",
            "            46          -0.35015        0.429\n",
            "            47          -0.34986        0.429\n",
            "            48          -0.34958        0.429\n",
            "            49          -0.34932        0.429\n",
            "         Final          -0.34907        0.429\n",
            "veselă\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.333\n",
            "             2          -0.63430        0.333\n",
            "             3          -0.60787        0.333\n",
            "             4          -0.59289        0.333\n",
            "             5          -0.58326        0.333\n",
            "             6          -0.57654        0.333\n",
            "             7          -0.57159        0.333\n",
            "             8          -0.56780        0.333\n",
            "             9          -0.56479        0.333\n",
            "            10          -0.56235        0.333\n",
            "            11          -0.56034        0.333\n",
            "            12          -0.55864        0.333\n",
            "            13          -0.55719        0.333\n",
            "            14          -0.55594        0.333\n",
            "            15          -0.55486        0.333\n",
            "            16          -0.55390        0.333\n",
            "            17          -0.55305        0.333\n",
            "            18          -0.55229        0.333\n",
            "            19          -0.55162        0.333\n",
            "            20          -0.55100        0.333\n",
            "            21          -0.55045        0.333\n",
            "            22          -0.54994        0.333\n",
            "            23          -0.54947        0.333\n",
            "            24          -0.54905        0.333\n",
            "            25          -0.54865        0.333\n",
            "            26          -0.54829        0.333\n",
            "            27          -0.54795        0.333\n",
            "            28          -0.54764        0.333\n",
            "            29          -0.54735        0.333\n",
            "            30          -0.54707        0.333\n",
            "            31          -0.54682        0.333\n",
            "            32          -0.54658        0.333\n",
            "            33          -0.54635        0.333\n",
            "            34          -0.54614        0.333\n",
            "            35          -0.54594        0.333\n",
            "            36          -0.54575        0.333\n",
            "            37          -0.54557        0.333\n",
            "            38          -0.54540        0.333\n",
            "            39          -0.54524        0.333\n",
            "            40          -0.54508        0.333\n",
            "            41          -0.54494        0.333\n",
            "            42          -0.54480        0.333\n",
            "            43          -0.54466        0.333\n",
            "            44          -0.54454        0.333\n",
            "            45          -0.54441        0.333\n",
            "            46          -0.54430        0.333\n",
            "            47          -0.54419        0.333\n",
            "            48          -0.54408        0.333\n",
            "            49          -0.54398        0.333\n",
            "         Final          -0.54388        0.333\n",
            "vâna\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.333\n",
            "             2          -0.51842        1.000\n",
            "             3          -0.43447        1.000\n",
            "             4          -0.38499        1.000\n",
            "             5          -0.35220        1.000\n",
            "             6          -0.32879        1.000\n",
            "             7          -0.31119        1.000\n",
            "             8          -0.29745        1.000\n",
            "             9          -0.28642        1.000\n",
            "            10          -0.27735        1.000\n",
            "            11          -0.26975        1.000\n",
            "            12          -0.26330        1.000\n",
            "            13          -0.25775        1.000\n",
            "            14          -0.25291        1.000\n",
            "            15          -0.24867        1.000\n",
            "            16          -0.24491        1.000\n",
            "            17          -0.24156        1.000\n",
            "            18          -0.23855        1.000\n",
            "            19          -0.23583        1.000\n",
            "            20          -0.23337        1.000\n",
            "            21          -0.23112        1.000\n",
            "            22          -0.22906        1.000\n",
            "            23          -0.22717        1.000\n",
            "            24          -0.22543        1.000\n",
            "            25          -0.22382        1.000\n",
            "            26          -0.22232        1.000\n",
            "            27          -0.22093        1.000\n",
            "            28          -0.21964        1.000\n",
            "            29          -0.21842        1.000\n",
            "            30          -0.21729        1.000\n",
            "            31          -0.21622        1.000\n",
            "            32          -0.21522        1.000\n",
            "            33          -0.21427        1.000\n",
            "            34          -0.21338        1.000\n",
            "            35          -0.21253        1.000\n",
            "            36          -0.21173        1.000\n",
            "            37          -0.21098        1.000\n",
            "            38          -0.21026        1.000\n",
            "            39          -0.20957        1.000\n",
            "            40          -0.20892        1.000\n",
            "            41          -0.20830        1.000\n",
            "            42          -0.20770        1.000\n",
            "            43          -0.20714        1.000\n",
            "            44          -0.20659        1.000\n",
            "            45          -0.20608        1.000\n",
            "            46          -0.20558        1.000\n",
            "            47          -0.20510        1.000\n",
            "            48          -0.20464        1.000\n",
            "            49          -0.20420        1.000\n",
            "         Final          -0.20378        1.000\n",
            "umbrele\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.250\n",
            "             2          -1.38629        0.250\n",
            "             3          -1.38629        0.250\n",
            "             4          -1.38629        0.250\n",
            "             5          -1.38629        0.250\n",
            "             6          -1.38629        0.250\n",
            "             7          -1.38629        0.250\n",
            "             8          -1.38629        0.250\n",
            "             9          -1.38629        0.250\n",
            "            10          -1.38629        0.250\n",
            "            11          -1.38629        0.250\n",
            "            12          -1.38629        0.250\n",
            "            13          -1.38629        0.250\n",
            "            14          -1.38629        0.250\n",
            "            15          -1.38629        0.250\n",
            "            16          -1.38629        0.250\n",
            "            17          -1.38629        0.250\n",
            "            18          -1.38629        0.250\n",
            "            19          -1.38629        0.250\n",
            "            20          -1.38629        0.250\n",
            "            21          -1.38629        0.250\n",
            "            22          -1.38629        0.250\n",
            "            23          -1.38629        0.250\n",
            "            24          -1.38629        0.250\n",
            "            25          -1.38629        0.250\n",
            "            26          -1.38629        0.250\n",
            "            27          -1.38629        0.250\n",
            "            28          -1.38629        0.250\n",
            "            29          -1.38629        0.250\n",
            "            30          -1.38629        0.250\n",
            "            31          -1.38629        0.250\n",
            "            32          -1.38629        0.250\n",
            "            33          -1.38629        0.250\n",
            "            34          -1.38629        0.250\n",
            "            35          -1.38629        0.250\n",
            "            36          -1.38629        0.250\n",
            "            37          -1.38629        0.250\n",
            "            38          -1.38629        0.250\n",
            "            39          -1.38629        0.250\n",
            "            40          -1.38629        0.250\n",
            "            41          -1.38629        0.250\n",
            "            42          -1.38629        0.250\n",
            "            43          -1.38629        0.250\n",
            "            44          -1.38629        0.250\n",
            "            45          -1.38629        0.250\n",
            "            46          -1.38629        0.250\n",
            "            47          -1.38629        0.250\n",
            "            48          -1.38629        0.250\n",
            "            49          -1.38629        0.250\n",
            "         Final          -1.38629        0.250\n",
            "turele\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1           0.00000        1.000\n",
            "             2           0.00000        1.000\n",
            "             3           0.00000        1.000\n",
            "             4           0.00000        1.000\n",
            "             5           0.00000        1.000\n",
            "             6           0.00000        1.000\n",
            "             7           0.00000        1.000\n",
            "             8           0.00000        1.000\n",
            "             9           0.00000        1.000\n",
            "            10           0.00000        1.000\n",
            "            11           0.00000        1.000\n",
            "            12           0.00000        1.000\n",
            "            13           0.00000        1.000\n",
            "            14           0.00000        1.000\n",
            "            15           0.00000        1.000\n",
            "            16           0.00000        1.000\n",
            "            17           0.00000        1.000\n",
            "            18           0.00000        1.000\n",
            "            19           0.00000        1.000\n",
            "            20           0.00000        1.000\n",
            "            21           0.00000        1.000\n",
            "            22           0.00000        1.000\n",
            "            23           0.00000        1.000\n",
            "            24           0.00000        1.000\n",
            "            25           0.00000        1.000\n",
            "            26           0.00000        1.000\n",
            "            27           0.00000        1.000\n",
            "            28           0.00000        1.000\n",
            "            29           0.00000        1.000\n",
            "            30           0.00000        1.000\n",
            "            31           0.00000        1.000\n",
            "            32           0.00000        1.000\n",
            "            33           0.00000        1.000\n",
            "            34           0.00000        1.000\n",
            "            35           0.00000        1.000\n",
            "            36           0.00000        1.000\n",
            "            37           0.00000        1.000\n",
            "            38           0.00000        1.000\n",
            "            39           0.00000        1.000\n",
            "            40           0.00000        1.000\n",
            "            41           0.00000        1.000\n",
            "            42           0.00000        1.000\n",
            "            43           0.00000        1.000\n",
            "            44           0.00000        1.000\n",
            "            45           0.00000        1.000\n",
            "            46           0.00000        1.000\n",
            "            47           0.00000        1.000\n",
            "            48           0.00000        1.000\n",
            "            49           0.00000        1.000\n",
            "         Final           0.00000        1.000\n",
            "torturi\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.500\n",
            "             2          -0.69315        0.500\n",
            "             3          -0.69315        0.500\n",
            "             4          -0.69315        0.500\n",
            "             5          -0.69315        0.500\n",
            "             6          -0.69315        0.500\n",
            "             7          -0.69315        0.500\n",
            "             8          -0.69315        0.500\n",
            "             9          -0.69315        0.500\n",
            "            10          -0.69315        0.500\n",
            "            11          -0.69315        0.500\n",
            "            12          -0.69315        0.500\n",
            "            13          -0.69315        0.500\n",
            "            14          -0.69315        0.500\n",
            "            15          -0.69315        0.500\n",
            "            16          -0.69315        0.500\n",
            "            17          -0.69315        0.500\n",
            "            18          -0.69315        0.500\n",
            "            19          -0.69315        0.500\n",
            "            20          -0.69315        0.500\n",
            "            21          -0.69315        0.500\n",
            "            22          -0.69315        0.500\n",
            "            23          -0.69315        0.500\n",
            "            24          -0.69315        0.500\n",
            "            25          -0.69315        0.500\n",
            "            26          -0.69315        0.500\n",
            "            27          -0.69315        0.500\n",
            "            28          -0.69315        0.500\n",
            "            29          -0.69315        0.500\n",
            "            30          -0.69315        0.500\n",
            "            31          -0.69315        0.500\n",
            "            32          -0.69315        0.500\n",
            "            33          -0.69315        0.500\n",
            "            34          -0.69315        0.500\n",
            "            35          -0.69315        0.500\n",
            "            36          -0.69315        0.500\n",
            "            37          -0.69315        0.500\n",
            "            38          -0.69315        0.500\n",
            "            39          -0.69315        0.500\n",
            "            40          -0.69315        0.500\n",
            "            41          -0.69315        0.500\n",
            "            42          -0.69315        0.500\n",
            "            43          -0.69315        0.500\n",
            "            44          -0.69315        0.500\n",
            "            45          -0.69315        0.500\n",
            "            46          -0.69315        0.500\n",
            "            47          -0.69315        0.500\n",
            "            48          -0.69315        0.500\n",
            "            49          -0.69315        0.500\n",
            "         Final          -0.69315        0.500\n",
            "toc\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.500\n",
            "             2          -0.42164        1.000\n",
            "             3          -0.30084        1.000\n",
            "             4          -0.23250        1.000\n",
            "             5          -0.18866        1.000\n",
            "             6          -0.15826        1.000\n",
            "             7          -0.13602        1.000\n",
            "             8          -0.11909        1.000\n",
            "             9          -0.10580        1.000\n",
            "            10          -0.09510        1.000\n",
            "            11          -0.08632        1.000\n",
            "            12          -0.07898        1.000\n",
            "            13          -0.07277        1.000\n",
            "            14          -0.06744        1.000\n",
            "            15          -0.06283        1.000\n",
            "            16          -0.05880        1.000\n",
            "            17          -0.05524        1.000\n",
            "            18          -0.05208        1.000\n",
            "            19          -0.04926        1.000\n",
            "            20          -0.04672        1.000\n",
            "            21          -0.04443        1.000\n",
            "            22          -0.04235        1.000\n",
            "            23          -0.04045        1.000\n",
            "            24          -0.03872        1.000\n",
            "            25          -0.03712        1.000\n",
            "            26          -0.03565        1.000\n",
            "            27          -0.03429        1.000\n",
            "            28          -0.03303        1.000\n",
            "            29          -0.03186        1.000\n",
            "            30          -0.03076        1.000\n",
            "            31          -0.02974        1.000\n",
            "            32          -0.02878        1.000\n",
            "            33          -0.02789        1.000\n",
            "            34          -0.02704        1.000\n",
            "            35          -0.02625        1.000\n",
            "            36          -0.02550        1.000\n",
            "            37          -0.02479        1.000\n",
            "            38          -0.02412        1.000\n",
            "            39          -0.02349        1.000\n",
            "            40          -0.02288        1.000\n",
            "            41          -0.02231        1.000\n",
            "            42          -0.02176        1.000\n",
            "            43          -0.02124        1.000\n",
            "            44          -0.02075        1.000\n",
            "            45          -0.02028        1.000\n",
            "            46          -0.01982        1.000\n",
            "            47          -0.01939        1.000\n",
            "            48          -0.01898        1.000\n",
            "            49          -0.01858        1.000\n",
            "         Final          -0.01820        1.000\n",
            "sare\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.600\n",
            "             2          -0.49369        0.600\n",
            "             3          -0.41057        0.600\n",
            "             4          -0.36596        0.600\n",
            "             5          -0.33830        0.600\n",
            "             6          -0.31953        0.600\n",
            "             7          -0.30598        0.600\n",
            "             8          -0.29574        0.600\n",
            "             9          -0.28774        0.600\n",
            "            10          -0.28132        0.600\n",
            "            11          -0.27606        0.600\n",
            "            12          -0.27166        0.600\n",
            "            13          -0.26794        0.600\n",
            "            14          -0.26474        0.600\n",
            "            15          -0.26197        0.600\n",
            "            16          -0.25954        0.600\n",
            "            17          -0.25740        0.600\n",
            "            18          -0.25549        0.600\n",
            "            19          -0.25379        0.600\n",
            "            20          -0.25225        0.600\n",
            "            21          -0.25087        0.600\n",
            "            22          -0.24960        0.600\n",
            "            23          -0.24845        0.600\n",
            "            24          -0.24739        0.600\n",
            "            25          -0.24642        0.600\n",
            "            26          -0.24552        0.600\n",
            "            27          -0.24469        0.600\n",
            "            28          -0.24392        0.600\n",
            "            29          -0.24320        0.600\n",
            "            30          -0.24253        0.600\n",
            "            31          -0.24190        0.600\n",
            "            32          -0.24132        0.600\n",
            "            33          -0.24076        0.600\n",
            "            34          -0.24024        0.600\n",
            "            35          -0.23975        0.600\n",
            "            36          -0.23929        0.600\n",
            "            37          -0.23885        0.600\n",
            "            38          -0.23844        0.600\n",
            "            39          -0.23805        0.600\n",
            "            40          -0.23767        0.600\n",
            "            41          -0.23732        0.600\n",
            "            42          -0.23698        0.600\n",
            "            43          -0.23666        0.600\n",
            "            44          -0.23635        0.600\n",
            "            45          -0.23605        0.600\n",
            "            46          -0.23577        0.600\n",
            "            47          -0.23550        0.600\n",
            "            48          -0.23524        0.600\n",
            "            49          -0.23500        0.600\n",
            "         Final          -0.23476        0.600\n",
            "republica\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.571\n",
            "             2          -0.69315        0.571\n",
            "             3          -0.69315        0.571\n",
            "             4          -0.69315        0.571\n",
            "             5          -0.69315        0.571\n",
            "             6          -0.69315        0.571\n",
            "             7          -0.69315        0.571\n",
            "             8          -0.69315        0.571\n",
            "             9          -0.69315        0.571\n",
            "            10          -0.69315        0.571\n",
            "            11          -0.69315        0.571\n",
            "            12          -0.69315        0.571\n",
            "            13          -0.69315        0.571\n",
            "            14          -0.69315        0.571\n",
            "            15          -0.69315        0.571\n",
            "            16          -0.69315        0.571\n",
            "            17          -0.69315        0.571\n",
            "            18          -0.69315        0.571\n",
            "            19          -0.69315        0.571\n",
            "            20          -0.69315        0.571\n",
            "            21          -0.69315        0.571\n",
            "            22          -0.69315        0.571\n",
            "            23          -0.69315        0.571\n",
            "            24          -0.69315        0.571\n",
            "            25          -0.69315        0.571\n",
            "            26          -0.69315        0.571\n",
            "            27          -0.69315        0.571\n",
            "            28          -0.69315        0.571\n",
            "            29          -0.69315        0.571\n",
            "            30          -0.69315        0.571\n",
            "            31          -0.69315        0.571\n",
            "            32          -0.69315        0.571\n",
            "            33          -0.69315        0.571\n",
            "            34          -0.69315        0.571\n",
            "            35          -0.69315        0.571\n",
            "            36          -0.69315        0.571\n",
            "            37          -0.69315        0.571\n",
            "            38          -0.69315        0.571\n",
            "            39          -0.69315        0.571\n",
            "            40          -0.69315        0.571\n",
            "            41          -0.69315        0.571\n",
            "            42          -0.69315        0.571\n",
            "            43          -0.69315        0.571\n",
            "            44          -0.69315        0.571\n",
            "            45          -0.69315        0.571\n",
            "            46          -0.69315        0.571\n",
            "            47          -0.69315        0.571\n",
            "            48          -0.69315        0.571\n",
            "            49          -0.69315        0.571\n",
            "         Final          -0.69315        0.571\n",
            "paria\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.500\n",
            "             2          -0.48419        1.000\n",
            "             3          -0.36676        1.000\n",
            "             4          -0.29345        1.000\n",
            "             5          -0.24387        1.000\n",
            "             6          -0.20829        1.000\n",
            "             7          -0.18158        1.000\n",
            "             8          -0.16084        1.000\n",
            "             9          -0.14428        1.000\n",
            "            10          -0.13076        1.000\n",
            "            11          -0.11953        1.000\n",
            "            12          -0.11004        1.000\n",
            "            13          -0.10194        1.000\n",
            "            14          -0.09492        1.000\n",
            "            15          -0.08880        1.000\n",
            "            16          -0.08342        1.000\n",
            "            17          -0.07864        1.000\n",
            "            18          -0.07437        1.000\n",
            "            19          -0.07053        1.000\n",
            "            20          -0.06707        1.000\n",
            "            21          -0.06393        1.000\n",
            "            22          -0.06107        1.000\n",
            "            23          -0.05845        1.000\n",
            "            24          -0.05604        1.000\n",
            "            25          -0.05382        1.000\n",
            "            26          -0.05177        1.000\n",
            "            27          -0.04986        1.000\n",
            "            28          -0.04810        1.000\n",
            "            29          -0.04645        1.000\n",
            "            30          -0.04491        1.000\n",
            "            31          -0.04346        1.000\n",
            "            32          -0.04211        1.000\n",
            "            33          -0.04084        1.000\n",
            "            34          -0.03964        1.000\n",
            "            35          -0.03851        1.000\n",
            "            36          -0.03744        1.000\n",
            "            37          -0.03643        1.000\n",
            "            38          -0.03547        1.000\n",
            "            39          -0.03456        1.000\n",
            "            40          -0.03370        1.000\n",
            "            41          -0.03287        1.000\n",
            "            42          -0.03209        1.000\n",
            "            43          -0.03134        1.000\n",
            "            44          -0.03063        1.000\n",
            "            45          -0.02995        1.000\n",
            "            46          -0.02929        1.000\n",
            "            47          -0.02867        1.000\n",
            "            48          -0.02807        1.000\n",
            "            49          -0.02750        1.000\n",
            "         Final          -0.02694        1.000\n",
            "somn\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.667\n",
            "             2          -0.48714        0.833\n",
            "             3          -0.38437        1.000\n",
            "             4          -0.31980        1.000\n",
            "             5          -0.27418        1.000\n",
            "             6          -0.23984        1.000\n",
            "             7          -0.21295        1.000\n",
            "             8          -0.19130        1.000\n",
            "             9          -0.17350        1.000\n",
            "            10          -0.15862        1.000\n",
            "            11          -0.14600        1.000\n",
            "            12          -0.13517        1.000\n",
            "            13          -0.12578        1.000\n",
            "            14          -0.11757        1.000\n",
            "            15          -0.11033        1.000\n",
            "            16          -0.10390        1.000\n",
            "            17          -0.09816        1.000\n",
            "            18          -0.09300        1.000\n",
            "            19          -0.08834        1.000\n",
            "            20          -0.08412        1.000\n",
            "            21          -0.08027        1.000\n",
            "            22          -0.07675        1.000\n",
            "            23          -0.07351        1.000\n",
            "            24          -0.07053        1.000\n",
            "            25          -0.06778        1.000\n",
            "            26          -0.06523        1.000\n",
            "            27          -0.06287        1.000\n",
            "            28          -0.06066        1.000\n",
            "            29          -0.05860        1.000\n",
            "            30          -0.05667        1.000\n",
            "            31          -0.05487        1.000\n",
            "            32          -0.05317        1.000\n",
            "            33          -0.05157        1.000\n",
            "            34          -0.05007        1.000\n",
            "            35          -0.04864        1.000\n",
            "            36          -0.04730        1.000\n",
            "            37          -0.04603        1.000\n",
            "            38          -0.04482        1.000\n",
            "            39          -0.04367        1.000\n",
            "            40          -0.04258        1.000\n",
            "            41          -0.04154        1.000\n",
            "            42          -0.04055        1.000\n",
            "            43          -0.03961        1.000\n",
            "            44          -0.03871        1.000\n",
            "            45          -0.03785        1.000\n",
            "            46          -0.03702        1.000\n",
            "            47          -0.03623        1.000\n",
            "            48          -0.03547        1.000\n",
            "            49          -0.03474        1.000\n",
            "         Final          -0.03405        1.000\n",
            "post\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.500\n",
            "             2          -0.42992        1.000\n",
            "             3          -0.30687        1.000\n",
            "             4          -0.23598        1.000\n",
            "             5          -0.19037        1.000\n",
            "             6          -0.15886        1.000\n",
            "             7          -0.13592        1.000\n",
            "             8          -0.11856        1.000\n",
            "             9          -0.10499        1.000\n",
            "            10          -0.09412        1.000\n",
            "            11          -0.08523        1.000\n",
            "            12          -0.07783        1.000\n",
            "            13          -0.07159        1.000\n",
            "            14          -0.06625        1.000\n",
            "            15          -0.06164        1.000\n",
            "            16          -0.05762        1.000\n",
            "            17          -0.05408        1.000\n",
            "            18          -0.05094        1.000\n",
            "            19          -0.04814        1.000\n",
            "            20          -0.04563        1.000\n",
            "            21          -0.04336        1.000\n",
            "            22          -0.04130        1.000\n",
            "            23          -0.03943        1.000\n",
            "            24          -0.03772        1.000\n",
            "            25          -0.03615        1.000\n",
            "            26          -0.03470        1.000\n",
            "            27          -0.03336        1.000\n",
            "            28          -0.03213        1.000\n",
            "            29          -0.03097        1.000\n",
            "            30          -0.02990        1.000\n",
            "            31          -0.02890        1.000\n",
            "            32          -0.02796        1.000\n",
            "            33          -0.02708        1.000\n",
            "            34          -0.02626        1.000\n",
            "            35          -0.02548        1.000\n",
            "            36          -0.02475        1.000\n",
            "            37          -0.02406        1.000\n",
            "            38          -0.02340        1.000\n",
            "            39          -0.02278        1.000\n",
            "            40          -0.02219        1.000\n",
            "            41          -0.02163        1.000\n",
            "            42          -0.02110        1.000\n",
            "            43          -0.02059        1.000\n",
            "            44          -0.02011        1.000\n",
            "            45          -0.01965        1.000\n",
            "            46          -0.01921        1.000\n",
            "            47          -0.01879        1.000\n",
            "            48          -0.01838        1.000\n",
            "            49          -0.01800        1.000\n",
            "         Final          -0.01763        1.000\n",
            "sol\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.400\n",
            "             2          -0.45955        1.000\n",
            "             3          -0.35487        1.000\n",
            "             4          -0.29019        1.000\n",
            "             5          -0.24489        1.000\n",
            "             6          -0.21120        1.000\n",
            "             7          -0.18520        1.000\n",
            "             8          -0.16458        1.000\n",
            "             9          -0.14788        1.000\n",
            "            10          -0.13411        1.000\n",
            "            11          -0.12257        1.000\n",
            "            12          -0.11279        1.000\n",
            "            13          -0.10440        1.000\n",
            "            14          -0.09712        1.000\n",
            "            15          -0.09076        1.000\n",
            "            16          -0.08516        1.000\n",
            "            17          -0.08019        1.000\n",
            "            18          -0.07575        1.000\n",
            "            19          -0.07177        1.000\n",
            "            20          -0.06817        1.000\n",
            "            21          -0.06491        1.000\n",
            "            22          -0.06193        1.000\n",
            "            23          -0.05922        1.000\n",
            "            24          -0.05672        1.000\n",
            "            25          -0.05443        1.000\n",
            "            26          -0.05230        1.000\n",
            "            27          -0.05034        1.000\n",
            "            28          -0.04851        1.000\n",
            "            29          -0.04681        1.000\n",
            "            30          -0.04523        1.000\n",
            "            31          -0.04374        1.000\n",
            "            32          -0.04235        1.000\n",
            "            33          -0.04104        1.000\n",
            "            34          -0.03981        1.000\n",
            "            35          -0.03865        1.000\n",
            "            36          -0.03756        1.000\n",
            "            37          -0.03652        1.000\n",
            "            38          -0.03554        1.000\n",
            "            39          -0.03461        1.000\n",
            "            40          -0.03373        1.000\n",
            "            41          -0.03289        1.000\n",
            "            42          -0.03209        1.000\n",
            "            43          -0.03132        1.000\n",
            "            44          -0.03060        1.000\n",
            "            45          -0.02990        1.000\n",
            "            46          -0.02924        1.000\n",
            "            47          -0.02860        1.000\n",
            "            48          -0.02799        1.000\n",
            "            49          -0.02741        1.000\n",
            "         Final          -0.02685        1.000\n",
            "poartă\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.333\n",
            "             2          -0.96247        0.333\n",
            "             3          -0.91366        0.333\n",
            "             4          -0.88862        0.333\n",
            "             5          -0.87338        0.333\n",
            "             6          -0.86314        0.333\n",
            "             7          -0.85579        0.333\n",
            "             8          -0.85025        0.333\n",
            "             9          -0.84592        0.333\n",
            "            10          -0.84246        0.333\n",
            "            11          -0.83962        0.333\n",
            "            12          -0.83724        0.333\n",
            "            13          -0.83523        0.333\n",
            "            14          -0.83351        0.333\n",
            "            15          -0.83201        0.333\n",
            "            16          -0.83070        0.333\n",
            "            17          -0.82955        0.333\n",
            "            18          -0.82852        0.333\n",
            "            19          -0.82760        0.333\n",
            "            20          -0.82677        0.333\n",
            "            21          -0.82602        0.333\n",
            "            22          -0.82533        0.333\n",
            "            23          -0.82471        0.333\n",
            "            24          -0.82414        0.333\n",
            "            25          -0.82361        0.333\n",
            "            26          -0.82312        0.333\n",
            "            27          -0.82267        0.333\n",
            "            28          -0.82226        0.333\n",
            "            29          -0.82187        0.333\n",
            "            30          -0.82150        0.333\n",
            "            31          -0.82116        0.333\n",
            "            32          -0.82084        0.333\n",
            "            33          -0.82054        0.333\n",
            "            34          -0.82026        0.333\n",
            "            35          -0.82000        0.333\n",
            "            36          -0.81974        0.333\n",
            "            37          -0.81951        0.333\n",
            "            38          -0.81928        0.333\n",
            "            39          -0.81907        0.333\n",
            "            40          -0.81887        0.333\n",
            "            41          -0.81867        0.333\n",
            "            42          -0.81849        0.333\n",
            "            43          -0.81831        0.333\n",
            "            44          -0.81815        0.333\n",
            "            45          -0.81799        0.333\n",
            "            46          -0.81783        0.333\n",
            "            47          -0.81769        0.333\n",
            "            48          -0.81755        0.333\n",
            "            49          -0.81741        0.333\n",
            "         Final          -0.81728        0.333\n",
            "ochi\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.429\n",
            "             2          -0.71922        1.000\n",
            "             3          -0.51896        1.000\n",
            "             4          -0.40082        1.000\n",
            "             5          -0.32445        1.000\n",
            "             6          -0.27158        1.000\n",
            "             7          -0.23304        1.000\n",
            "             8          -0.20379        1.000\n",
            "             9          -0.18090        1.000\n",
            "            10          -0.16251        1.000\n",
            "            11          -0.14744        1.000\n",
            "            12          -0.13487        1.000\n",
            "            13          -0.12423        1.000\n",
            "            14          -0.11512        1.000\n",
            "            15          -0.10723        1.000\n",
            "            16          -0.10034        1.000\n",
            "            17          -0.09426        1.000\n",
            "            18          -0.08886        1.000\n",
            "            19          -0.08404        1.000\n",
            "            20          -0.07971        1.000\n",
            "            21          -0.07580        1.000\n",
            "            22          -0.07225        1.000\n",
            "            23          -0.06901        1.000\n",
            "            24          -0.06604        1.000\n",
            "            25          -0.06332        1.000\n",
            "            26          -0.06081        1.000\n",
            "            27          -0.05849        1.000\n",
            "            28          -0.05633        1.000\n",
            "            29          -0.05433        1.000\n",
            "            30          -0.05247        1.000\n",
            "            31          -0.05072        1.000\n",
            "            32          -0.04909        1.000\n",
            "            33          -0.04756        1.000\n",
            "            34          -0.04612        1.000\n",
            "            35          -0.04476        1.000\n",
            "            36          -0.04348        1.000\n",
            "            37          -0.04227        1.000\n",
            "            38          -0.04113        1.000\n",
            "            39          -0.04005        1.000\n",
            "            40          -0.03902        1.000\n",
            "            41          -0.03804        1.000\n",
            "            42          -0.03711        1.000\n",
            "            43          -0.03622        1.000\n",
            "            44          -0.03538        1.000\n",
            "            45          -0.03457        1.000\n",
            "            46          -0.03380        1.000\n",
            "            47          -0.03306        1.000\n",
            "            48          -0.03235        1.000\n",
            "            49          -0.03168        1.000\n",
            "         Final          -0.03103        1.000\n",
            "mobilă\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1           0.00000        1.000\n",
            "             2           0.00000        1.000\n",
            "             3           0.00000        1.000\n",
            "             4           0.00000        1.000\n",
            "             5           0.00000        1.000\n",
            "             6           0.00000        1.000\n",
            "             7           0.00000        1.000\n",
            "             8           0.00000        1.000\n",
            "             9           0.00000        1.000\n",
            "            10           0.00000        1.000\n",
            "            11           0.00000        1.000\n",
            "            12           0.00000        1.000\n",
            "            13           0.00000        1.000\n",
            "            14           0.00000        1.000\n",
            "            15           0.00000        1.000\n",
            "            16           0.00000        1.000\n",
            "            17           0.00000        1.000\n",
            "            18           0.00000        1.000\n",
            "            19           0.00000        1.000\n",
            "            20           0.00000        1.000\n",
            "            21           0.00000        1.000\n",
            "            22           0.00000        1.000\n",
            "            23           0.00000        1.000\n",
            "            24           0.00000        1.000\n",
            "            25           0.00000        1.000\n",
            "            26           0.00000        1.000\n",
            "            27           0.00000        1.000\n",
            "            28           0.00000        1.000\n",
            "            29           0.00000        1.000\n",
            "            30           0.00000        1.000\n",
            "            31           0.00000        1.000\n",
            "            32           0.00000        1.000\n",
            "            33           0.00000        1.000\n",
            "            34           0.00000        1.000\n",
            "            35           0.00000        1.000\n",
            "            36           0.00000        1.000\n",
            "            37           0.00000        1.000\n",
            "            38           0.00000        1.000\n",
            "            39           0.00000        1.000\n",
            "            40           0.00000        1.000\n",
            "            41           0.00000        1.000\n",
            "            42           0.00000        1.000\n",
            "            43           0.00000        1.000\n",
            "            44           0.00000        1.000\n",
            "            45           0.00000        1.000\n",
            "            46           0.00000        1.000\n",
            "            47           0.00000        1.000\n",
            "            48           0.00000        1.000\n",
            "            49           0.00000        1.000\n",
            "         Final           0.00000        1.000\n",
            "mie\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.500\n",
            "             2          -0.55035        0.833\n",
            "             3          -0.46461        0.833\n",
            "             4          -0.40772        0.833\n",
            "             5          -0.36710        0.833\n",
            "             6          -0.33649        0.833\n",
            "             7          -0.31248        0.833\n",
            "             8          -0.29307        0.833\n",
            "             9          -0.27699        0.833\n",
            "            10          -0.26342        0.833\n",
            "            11          -0.25177        0.833\n",
            "            12          -0.24166        0.833\n",
            "            13          -0.23277        0.833\n",
            "            14          -0.22490        0.833\n",
            "            15          -0.21787        0.833\n",
            "            16          -0.21155        0.833\n",
            "            17          -0.20583        0.833\n",
            "            18          -0.20062        0.833\n",
            "            19          -0.19586        0.833\n",
            "            20          -0.19150        0.833\n",
            "            21          -0.18747        0.833\n",
            "            22          -0.18375        0.833\n",
            "            23          -0.18030        0.833\n",
            "            24          -0.17709        0.833\n",
            "            25          -0.17409        0.833\n",
            "            26          -0.17129        0.833\n",
            "            27          -0.16867        0.833\n",
            "            28          -0.16620        0.833\n",
            "            29          -0.16388        0.833\n",
            "            30          -0.16170        0.833\n",
            "            31          -0.15963        0.833\n",
            "            32          -0.15768        0.833\n",
            "            33          -0.15583        0.833\n",
            "            34          -0.15407        0.833\n",
            "            35          -0.15240        0.833\n",
            "            36          -0.15081        0.833\n",
            "            37          -0.14930        0.833\n",
            "            38          -0.14785        0.833\n",
            "            39          -0.14647        0.833\n",
            "            40          -0.14516        0.833\n",
            "            41          -0.14390        0.833\n",
            "            42          -0.14269        0.833\n",
            "            43          -0.14153        0.833\n",
            "            44          -0.14042        0.833\n",
            "            45          -0.13936        0.833\n",
            "            46          -0.13833        0.833\n",
            "            47          -0.13735        0.833\n",
            "            48          -0.13640        0.833\n",
            "            49          -0.13549        0.833\n",
            "         Final          -0.13461        0.833\n",
            "formă\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.600\n",
            "             2          -0.50487        1.000\n",
            "             3          -0.40139        1.000\n",
            "             4          -0.33415        1.000\n",
            "             5          -0.28638        1.000\n",
            "             6          -0.25052        1.000\n",
            "             7          -0.22257        1.000\n",
            "             8          -0.20014        1.000\n",
            "             9          -0.18176        1.000\n",
            "            10          -0.16641        1.000\n",
            "            11          -0.15340        1.000\n",
            "            12          -0.14225        1.000\n",
            "            13          -0.13257        1.000\n",
            "            14          -0.12411        1.000\n",
            "            15          -0.11664        1.000\n",
            "            16          -0.11000        1.000\n",
            "            17          -0.10406        1.000\n",
            "            18          -0.09872        1.000\n",
            "            19          -0.09389        1.000\n",
            "            20          -0.08951        1.000\n",
            "            21          -0.08551        1.000\n",
            "            22          -0.08184        1.000\n",
            "            23          -0.07847        1.000\n",
            "            24          -0.07537        1.000\n",
            "            25          -0.07249        1.000\n",
            "            26          -0.06983        1.000\n",
            "            27          -0.06734        1.000\n",
            "            28          -0.06503        1.000\n",
            "            29          -0.06287        1.000\n",
            "            30          -0.06085        1.000\n",
            "            31          -0.05895        1.000\n",
            "            32          -0.05716        1.000\n",
            "            33          -0.05548        1.000\n",
            "            34          -0.05389        1.000\n",
            "            35          -0.05239        1.000\n",
            "            36          -0.05097        1.000\n",
            "            37          -0.04962        1.000\n",
            "            38          -0.04835        1.000\n",
            "            39          -0.04713        1.000\n",
            "            40          -0.04598        1.000\n",
            "            41          -0.04488        1.000\n",
            "            42          -0.04383        1.000\n",
            "            43          -0.04282        1.000\n",
            "            44          -0.04186        1.000\n",
            "            45          -0.04095        1.000\n",
            "            46          -0.04007        1.000\n",
            "            47          -0.03923        1.000\n",
            "            48          -0.03842        1.000\n",
            "            49          -0.03765        1.000\n",
            "         Final          -0.03690        1.000\n",
            "corn\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1           0.00000        1.000\n",
            "             2           0.00000        1.000\n",
            "             3           0.00000        1.000\n",
            "             4           0.00000        1.000\n",
            "             5           0.00000        1.000\n",
            "             6           0.00000        1.000\n",
            "             7           0.00000        1.000\n",
            "             8           0.00000        1.000\n",
            "             9           0.00000        1.000\n",
            "            10           0.00000        1.000\n",
            "            11           0.00000        1.000\n",
            "            12           0.00000        1.000\n",
            "            13           0.00000        1.000\n",
            "            14           0.00000        1.000\n",
            "            15           0.00000        1.000\n",
            "            16           0.00000        1.000\n",
            "            17           0.00000        1.000\n",
            "            18           0.00000        1.000\n",
            "            19           0.00000        1.000\n",
            "            20           0.00000        1.000\n",
            "            21           0.00000        1.000\n",
            "            22           0.00000        1.000\n",
            "            23           0.00000        1.000\n",
            "            24           0.00000        1.000\n",
            "            25           0.00000        1.000\n",
            "            26           0.00000        1.000\n",
            "            27           0.00000        1.000\n",
            "            28           0.00000        1.000\n",
            "            29           0.00000        1.000\n",
            "            30           0.00000        1.000\n",
            "            31           0.00000        1.000\n",
            "            32           0.00000        1.000\n",
            "            33           0.00000        1.000\n",
            "            34           0.00000        1.000\n",
            "            35           0.00000        1.000\n",
            "            36           0.00000        1.000\n",
            "            37           0.00000        1.000\n",
            "            38           0.00000        1.000\n",
            "            39           0.00000        1.000\n",
            "            40           0.00000        1.000\n",
            "            41           0.00000        1.000\n",
            "            42           0.00000        1.000\n",
            "            43           0.00000        1.000\n",
            "            44           0.00000        1.000\n",
            "            45           0.00000        1.000\n",
            "            46           0.00000        1.000\n",
            "            47           0.00000        1.000\n",
            "            48           0.00000        1.000\n",
            "            49           0.00000        1.000\n",
            "         Final           0.00000        1.000\n",
            "fata\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.500\n",
            "             2          -0.69315        0.500\n",
            "             3          -0.69315        0.500\n",
            "             4          -0.69315        0.500\n",
            "             5          -0.69315        0.500\n",
            "             6          -0.69315        0.500\n",
            "             7          -0.69315        0.500\n",
            "             8          -0.69315        0.500\n",
            "             9          -0.69315        0.500\n",
            "            10          -0.69315        0.500\n",
            "            11          -0.69315        0.500\n",
            "            12          -0.69315        0.500\n",
            "            13          -0.69315        0.500\n",
            "            14          -0.69315        0.500\n",
            "            15          -0.69315        0.500\n",
            "            16          -0.69315        0.500\n",
            "            17          -0.69315        0.500\n",
            "            18          -0.69315        0.500\n",
            "            19          -0.69315        0.500\n",
            "            20          -0.69315        0.500\n",
            "            21          -0.69315        0.500\n",
            "            22          -0.69315        0.500\n",
            "            23          -0.69315        0.500\n",
            "            24          -0.69315        0.500\n",
            "            25          -0.69315        0.500\n",
            "            26          -0.69315        0.500\n",
            "            27          -0.69315        0.500\n",
            "            28          -0.69315        0.500\n",
            "            29          -0.69315        0.500\n",
            "            30          -0.69315        0.500\n",
            "            31          -0.69315        0.500\n",
            "            32          -0.69315        0.500\n",
            "            33          -0.69315        0.500\n",
            "            34          -0.69315        0.500\n",
            "            35          -0.69315        0.500\n",
            "            36          -0.69315        0.500\n",
            "            37          -0.69315        0.500\n",
            "            38          -0.69315        0.500\n",
            "            39          -0.69315        0.500\n",
            "            40          -0.69315        0.500\n",
            "            41          -0.69315        0.500\n",
            "            42          -0.69315        0.500\n",
            "            43          -0.69315        0.500\n",
            "            44          -0.69315        0.500\n",
            "            45          -0.69315        0.500\n",
            "            46          -0.69315        0.500\n",
            "            47          -0.69315        0.500\n",
            "            48          -0.69315        0.500\n",
            "            49          -0.69315        0.500\n",
            "         Final          -0.69315        0.500\n",
            "imobil\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1           0.00000        1.000\n",
            "             2           0.00000        1.000\n",
            "             3           0.00000        1.000\n",
            "             4           0.00000        1.000\n",
            "             5           0.00000        1.000\n",
            "             6           0.00000        1.000\n",
            "             7           0.00000        1.000\n",
            "             8           0.00000        1.000\n",
            "             9           0.00000        1.000\n",
            "            10           0.00000        1.000\n",
            "            11           0.00000        1.000\n",
            "            12           0.00000        1.000\n",
            "            13           0.00000        1.000\n",
            "            14           0.00000        1.000\n",
            "            15           0.00000        1.000\n",
            "            16           0.00000        1.000\n",
            "            17           0.00000        1.000\n",
            "            18           0.00000        1.000\n",
            "            19           0.00000        1.000\n",
            "            20           0.00000        1.000\n",
            "            21           0.00000        1.000\n",
            "            22           0.00000        1.000\n",
            "            23           0.00000        1.000\n",
            "            24           0.00000        1.000\n",
            "            25           0.00000        1.000\n",
            "            26           0.00000        1.000\n",
            "            27           0.00000        1.000\n",
            "            28           0.00000        1.000\n",
            "            29           0.00000        1.000\n",
            "            30           0.00000        1.000\n",
            "            31           0.00000        1.000\n",
            "            32           0.00000        1.000\n",
            "            33           0.00000        1.000\n",
            "            34           0.00000        1.000\n",
            "            35           0.00000        1.000\n",
            "            36           0.00000        1.000\n",
            "            37           0.00000        1.000\n",
            "            38           0.00000        1.000\n",
            "            39           0.00000        1.000\n",
            "            40           0.00000        1.000\n",
            "            41           0.00000        1.000\n",
            "            42           0.00000        1.000\n",
            "            43           0.00000        1.000\n",
            "            44           0.00000        1.000\n",
            "            45           0.00000        1.000\n",
            "            46           0.00000        1.000\n",
            "            47           0.00000        1.000\n",
            "            48           0.00000        1.000\n",
            "            49           0.00000        1.000\n",
            "         Final           0.00000        1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluarea modelelor de clasificare si realizarea unor statistici pe rezultate**"
      ],
      "metadata": {
        "id": "x-2d42y1MuRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision= {}\n",
        "recall = {}\n",
        "accuracy = {}\n",
        "for w in b.keys():\n",
        "  output_labels = classifiers[w].classify_many([x[0] for x in b[w]])\n",
        "  metrics = sklearn.metrics.classification_report( output_labels, [x[1] for x in b[w]],output_dict=True, zero_division=0)\n",
        "  l = [label for label in metrics.keys()  if type(metrics[label])==type(dict()) ]\n",
        "  precision[w] = sum([metrics[label]['precision'] for label in l  ])/len(l)\n",
        "  recall[w] = sum([metrics[label]['recall'] for label in l  ])/len(l)\n",
        "  accuracy[w] = metrics['accuracy']\n",
        "\n",
        "def min_score(d, metric):\n",
        "  min_v = min(d.values())\n",
        "  it = []\n",
        "  for k,v in d.items():\n",
        "    if v==min_v:\n",
        "      it.append((k,v))\n",
        "  print(\"Words with the worst \",metric,\":\",it)\n",
        "\n",
        "def max_score(d, metric):\n",
        "  max_v = max(d.values())\n",
        "  it = []\n",
        "  for k,v in d.items():\n",
        "    if v==max_v:\n",
        "      it.append((k,v))\n",
        "  print(\"Words with the best \",metric,\":\",it)\n",
        "\n",
        "def avg(d, metric):\n",
        "  av = sum(d.values())/len(d)\n",
        "  print(metric,\":\",av)\n",
        "\n",
        "min_score(precision,\"precision\")\n",
        "max_score(precision,\"precision\")\n",
        "avg(precision,\"precision\")\n",
        "\n",
        "min_score(recall,\"recall\")\n",
        "max_score(recall,\"recall\")\n",
        "avg(recall,\"recall\")\n",
        "\n",
        "min_score(accuracy,\"accuracy\")\n",
        "max_score(accuracy,\"accuracy\")\n",
        "avg(accuracy,\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhpuK9lGzmFF",
        "outputId": "c19749e5-8ec5-4ba2-bfaf-ce26448ba4cf"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words with the worst  precision : [('nouă', 0.2125)]\n",
            "Words with the best  precision : [('alpaca', 1.0), ('vâna', 1.0), ('turele', 1.0), ('mobilă', 1.0), ('corn', 1.0), ('imobil', 1.0)]\n",
            "precision : 0.6143903507193198\n",
            "Words with the worst  recall : [('nouă', 0.02361111111111111)]\n",
            "Words with the best  recall : [('alpaca', 1.0), ('vâna', 1.0), ('turele', 1.0), ('mobilă', 1.0), ('corn', 1.0), ('imobil', 1.0)]\n",
            "recall : 0.5021758878538465\n",
            "Words with the worst  accuracy : [('nouă', 0.1111111111111111)]\n",
            "Words with the best  accuracy : [('alpaca', 1.0), ('vâna', 1.0), ('turele', 1.0), ('mobilă', 1.0), ('corn', 1.0), ('imobil', 1.0)]\n",
            "accuracy : 0.5981597417521789\n"
          ]
        }
      ]
    }
  ]
}